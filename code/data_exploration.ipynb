{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook has been divided into 3 main modules:\n",
    "    \n",
    "    1) Extractive Summarization using spaCy language model\n",
    "    \n",
    "    2) Cosine Similarity of reddit posts\n",
    "    \n",
    "    3) LDA topic modeling of reddit comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2637,
     "status": "ok",
     "timestamp": 1607972756598,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "bjUHeLDZCTEr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6365,
     "status": "ok",
     "timestamp": 1607972760351,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "lrEh1jq9CYU0",
    "outputId": "da113bbf-a270-489c-914f-883bef031001"
   },
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11120,
     "status": "ok",
     "timestamp": 1607972765137,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "9w5lwoD-CZjN",
    "outputId": "a3448f29-959f-4843-d06e-bfd3f5bed733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyLDAvis in /Users/meenu/Library/Python/2.7/lib/python/site-packages (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (1.16.6)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (1.2.3)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (0.14.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (2.11.2)\n",
      "Requirement already satisfied: numexpr in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (2.7.1)\n",
      "Requirement already satisfied: pytest in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (4.6.11)\n",
      "Requirement already satisfied: future in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: funcy in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: pytz>=2011k in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from pandas>=0.17.0->pyLDAvis) (2013.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: funcsigs>=1.0; python_version < \"3.0\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (1.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (2.0.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (0.13.1)\n",
      "Requirement already satisfied: more-itertools<6.0.0,>=4.0.0; python_version <= \"2.7\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (5.0.0)\n",
      "Requirement already satisfied: wcwidth in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (0.2.5)\n",
      "Requirement already satisfied: pathlib2>=2.2.0; python_version < \"3.6\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (2.3.5)\n",
      "Requirement already satisfied: packaging in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (20.4)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pytest->pyLDAvis) (1.4.0)\n",
      "Requirement already satisfied: configparser>=3.5; python_version < \"3\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (4.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: contextlib2; python_version < \"3\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->pyLDAvis) (0.6.0.post1)\n",
      "Requirement already satisfied: backports.functools-lru-cache>=1.2.1; python_version < \"3.2\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from wcwidth->pytest->pyLDAvis) (1.6.1)\n",
      "Requirement already satisfied: scandir; python_version < \"3.5\" in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from pathlib2>=2.2.0; python_version < \"3.6\"->pytest->pyLDAvis) (1.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/meenu/Library/Python/2.7/lib/python/site-packages (from packaging->pytest->pyLDAvis) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18179,
     "status": "ok",
     "timestamp": 1607972772231,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "awcmyWmwCbeQ",
    "outputId": "a22cc11f-d8d9-401a-a285-1584f9d16200",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyod\n",
      "  Downloading pyod-0.8.4.tar.gz (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting combo\n",
      "  Downloading combo-0.1.1.tar.gz (37 kB)\n",
      "Requirement already satisfied: joblib in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (0.14.1)\n",
      "Requirement already satisfied: matplotlib in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.13 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (1.18.1)\n",
      "Requirement already satisfied: numba>=0.35 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (0.48.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (1.1.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (1.4.1)\n",
      "Requirement already satisfied: scikit_learn>=0.19.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (0.22.1)\n",
      "Requirement already satisfied: six in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (1.14.0)\n",
      "Requirement already satisfied: statsmodels in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pyod) (0.11.0)\n",
      "Collecting suod\n",
      "  Downloading suod-0.0.4.tar.gz (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 4.9 MB/s eta 0:00:01     |███████████████████████████▋    | 1.8 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (7.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->pyod) (2.4.6)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from numba>=0.35->pyod) (0.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from numba>=0.35->pyod) (46.0.0.post20200309)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.25->pyod) (2019.3)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from statsmodels->pyod) (0.5.1)\n",
      "Building wheels for collected packages: pyod, combo, suod\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyod: filename=pyod-0.8.4-py3-none-any.whl size=112081 sha256=8177476ec1389d7d513c82ce2fbd3a5ed0ba3d2a604df25e64eb92aada2cdb88\n",
      "  Stored in directory: /Users/meenu/Library/Caches/pip/wheels/9f/c9/60/b1311d6e5480f83f29e88bc6223ee1f011e0989a817ad01b65\n",
      "  Building wheel for combo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for combo: filename=combo-0.1.1-py3-none-any.whl size=42113 sha256=2f6be746462fe9051bdd9c329527e5ff6a980b7b8ba7580ec2652f847eff185f\n",
      "  Stored in directory: /Users/meenu/Library/Caches/pip/wheels/3e/e1/f8/08f19ba48f75d3dbbb549cec4b86cc0392c14b2b6bb81f4e1f\n",
      "  Building wheel for suod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for suod: filename=suod-0.0.4-py3-none-any.whl size=2167157 sha256=d8a6d6f975587d493c482c71cdb8aabf0cd582b6288f27cd1e2bbd323e746954\n",
      "  Stored in directory: /Users/meenu/Library/Caches/pip/wheels/dc/ae/aa/3b8cc857617f3ba6cb9e6b804c79c69d0ed60a08e022e9a4f3\n",
      "Successfully built pyod combo suod\n",
      "Installing collected packages: combo, suod, pyod\n",
      "Successfully installed combo-0.1.1 pyod-0.8.4 suod-0.0.4\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24948,
     "status": "ok",
     "timestamp": 1607972779018,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "lV1y8TBGCc4x",
    "outputId": "b292adfc-5e58-46f1-e9ff-77acd56e3169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27657,
     "status": "ok",
     "timestamp": 1607972781745,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "nA7lWD3DCe3h",
    "outputId": "748b877c-ffcc-4377-c2c6-2132607ef055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30334,
     "status": "ok",
     "timestamp": 1607972784445,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "tdg54VlnCf_Q",
    "outputId": "bc740575-bb83-4c5c-8bd3-ce798b86958b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (2.3.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (46.0.0.post20200309)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (4.51.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34552,
     "status": "ok",
     "timestamp": 1607972788688,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "RsYhK-DYCiRR",
    "outputId": "bc3b371f-639a-480d-f3ab-aebf41912c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.51.0)\n",
      "Requirement already satisfied: setuptools in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (46.0.0.post20200309)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.18.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# Download en\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37086,
     "status": "ok",
     "timestamp": 1607972791245,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "GN1j6wNUFAw-",
    "outputId": "3ba19eec-8296-4c7b-a91c-a55c1d62dde4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41495,
     "status": "ok",
     "timestamp": 1607972795684,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "HjrfYCN1CkMZ",
    "outputId": "3b58bbec-c76d-4731-e72f-a7693eb86065"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meenu/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/nltk/lm/vocabulary.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Counter, Iterable\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_custom_kernels.py:36: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_custom_kernels.cu' mode='r' encoding='utf8'>\n",
      "  SRC = (PWD / \"_custom_kernels.cu\").open(\"r\", encoding=\"utf8\").read()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_custom_kernels.py:39: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/thinc/neural/_murmur3.cu' mode='r' encoding='utf8'>\n",
      "  MMH_SRC = (PWD / \"_murmur3.cu\").open(\"r\", encoding=\"utf8\").read()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/wordcloud/wordcloud.py:31: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/wordcloud/stopwords' mode='r' encoding='UTF-8'>\n",
      "  STOPWORDS = set(map(str.strip, open(os.path.join(FILE, 'stopwords')).readlines()))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/meenu/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:546: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  class IteratorBase(collections.Iterator, trackable.Trackable,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "#Using Scipy for Hierarchical clustering - This allows us to plot Dendrogram\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import manifold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import silhouette_score,silhouette_samples\n",
    "\n",
    "import nltk # pip install nltk\n",
    "from nltk.corpus import stopwords # nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import spacy # pip install spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import gensim\n",
    "from gensim.models import word2vec  #pip install word2vec\n",
    "\n",
    "import textblob\n",
    "from wordcloud import WordCloud  #pip install wordcloud\n",
    "from textblob import TextBlob  #Sentiment Analysis - pip install textblob\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.python.ops import io_ops\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43332,
     "status": "ok",
     "timestamp": 1607972797541,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "rdhbUu6ZCm2c",
    "outputId": "319bd135-0e5c-4026-c511-4497de9d48ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47223,
     "status": "ok",
     "timestamp": 1607972801459,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "7l9R6JLOG-4_",
    "outputId": "ecf20580-7f16-4884-a041-9333b5b2f31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.1.0-py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websocket-client>=0.54.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 21.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting update-checker>=0.17\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting prawcore<2.0,>=1.3.0\n",
      "  Downloading prawcore-1.5.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from websocket-client>=0.54.0->praw) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from update-checker>=0.17->praw) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/meenu/opt/anaconda3/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.17->praw) (1.24.3)\n",
      "Installing collected packages: websocket-client, update-checker, prawcore, praw\n",
      "Successfully installed praw-7.1.0 prawcore-1.5.0 update-checker-0.18.0 websocket-client-0.57.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/Users/meenu/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 47210,
     "status": "ok",
     "timestamp": 1607972801462,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "iQSM3s0oEMb9"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "import praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 47203,
     "status": "ok",
     "timestamp": 1607972801464,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "z0xxAtBsS_uq"
   },
   "outputs": [],
   "source": [
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Extractive Text Summarization\n",
    "\n",
    "We have implemented extractive summarization to extract and concatenate important spans of the reddit comments. This is done by calculating the importance of each sentence based on the number of appearances of important keywords and their calculated normalized weights. Here each comment is tokenized using scaCy’s language model. \n",
    "\n",
    "This summarization model is only capable of picking the most important sentences from a document corpus but is not capable of generating new sentences to form a summary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gn92Ya9MG41g"
   },
   "source": [
    "## Scraping data from Reddit\n",
    "\n",
    "\n",
    "Posts and comments from the News, Worldnews, Science and Askscience subreddits are scraped using the PRAW reddit API. Each post consists of a title and many comments. All the comments under each post have been joined together. Our intention is to run the extractive summarization model over all the comments under each post and extract the top sentences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 47169,
     "status": "ok",
     "timestamp": 1607972801465,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "J3I25Tw2G6li"
   },
   "outputs": [],
   "source": [
    "#Connecting to the reddit client\n",
    "reddit = praw.Reddit(username = 'CandleZealousideal25',            \n",
    "password = 'Meens20!',            \n",
    "client_id = 'bn6D7tN21aOp-w',            \n",
    "client_secret = 'qs-250PRYA3Me7QPM6nR9y3MPDCtrA',            \n",
    "user_agent = 'Python chatbot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 338252,
     "status": "ok",
     "timestamp": 1607973092567,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "fhJ2_-bXHBMI"
   },
   "outputs": [],
   "source": [
    "#Selecting subreddits\n",
    "sub=['worldnews','news','askscience','science']\n",
    "\n",
    "posts=[]\n",
    "comments=[]\n",
    "\n",
    "#The sticked submission is at the top of hot listing of a subreddit assuming said submission isn't hidden by the currently authenticated user.\n",
    "\n",
    "for s in sub:\n",
    "    subreddit = reddit.subreddit(s)   # Chosing the subreddit\n",
    "    hot_python = subreddit.hot(limit=100) #Downloading the hot 100 posts\n",
    "    for submission in hot_python:\n",
    "\n",
    "        if not submission.stickied:\n",
    "            posts.append([submission.title,submission.selftext,submission.subreddit])\n",
    "            \n",
    "            submission.comments.replace_more(limit=0) \n",
    "            for comment in submission.comments.list():#If there are multiple comments under a single post\n",
    "                    if comment.parent() != submission.id: \n",
    "                        parent = str(comment.parent())\n",
    "                        posts.append([submission.title,comment.body,submission.subreddit])  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 338248,
     "status": "ok",
     "timestamp": 1607973092577,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "0JQ0yBjBIrAb"
   },
   "outputs": [],
   "source": [
    "#Converting list to dataframe\n",
    "posts = pd.DataFrame(posts,columns=['Title', 'Comments','subreddit'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 338223,
     "status": "ok",
     "timestamp": 1607973092578,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "8ZqRbATEP5yK",
    "outputId": "756bd20c-e26d-4b1c-b0f4-ff527b4fcf95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75 infected with COVID-19 after Santa visits n...</td>\n",
       "      <td></td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75 infected with COVID-19 after Santa visits n...</td>\n",
       "      <td>Yeh, who had the bright idea to bring a strang...</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75 infected with COVID-19 after Santa visits n...</td>\n",
       "      <td>You are exactly right.</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75 infected with COVID-19 after Santa visits n...</td>\n",
       "      <td>well hopefully at some point we'll actually va...</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75 infected with COVID-19 after Santa visits n...</td>\n",
       "      <td>My country shuts down everything beginning Wed...</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  ...  subreddit\n",
       "0  75 infected with COVID-19 after Santa visits n...  ...  worldnews\n",
       "1  75 infected with COVID-19 after Santa visits n...  ...  worldnews\n",
       "2  75 infected with COVID-19 after Santa visits n...  ...  worldnews\n",
       "3  75 infected with COVID-19 after Santa visits n...  ...  worldnews\n",
       "4  75 infected with COVID-19 after Santa visits n...  ...  worldnews\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1607973512364,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "6T99ELJ6P-pd",
    "outputId": "b3b4288c-217d-4139-ddec-95e18c66e379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique number of posts\n",
    "len(posts.Title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1607975164291,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "FwLoQ7GIRz6P",
    "outputId": "54c3deee-76fb-4b7b-9847-a3b8685e1d77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"An eye for an AI: Optic device mimics human r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'External source' causes oil tanker blast off ...</td>\n",
       "      <td>I'd think with oil this cheap and many places...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'New variant' of coronavirus identified - BBC</td>\n",
       "      <td>I don’t know much about this subject.\\n\\nBut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'New variant' of coronavirus identified - Hancock</td>\n",
       "      <td>Oh hey, look another copy and paste reply or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'New variant' of coronavirus identified in UK,...</td>\n",
       "      <td>*a* vaccine\\n\\n&gt;And the latest clinical advic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Young adults who increased social media use we...</td>\n",
       "      <td>In this case, it's not unlikely for people to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>how did scientists decide that proton has a \"p...</td>\n",
       "      <td>Hello! I am a ninth-grade student. My chemistr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>mRNA Vaccines: What happens to the antigen pre...</td>\n",
       "      <td>Looking at this: [https://www.cdc.gov/coronavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>when talking about climate change, why do we n...</td>\n",
       "      <td>Interesting but confusing. Are you able to ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>‘External source’ causes oil tanker blast off ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title                                           Comments\n",
       "0    \"An eye for an AI: Optic device mimics human r...                                                   \n",
       "1    'External source' causes oil tanker blast off ...   I'd think with oil this cheap and many places...\n",
       "2        'New variant' of coronavirus identified - BBC   I don’t know much about this subject.\\n\\nBut ...\n",
       "3    'New variant' of coronavirus identified - Hancock   Oh hey, look another copy and paste reply or ...\n",
       "4    'New variant' of coronavirus identified in UK,...   *a* vaccine\\n\\n>And the latest clinical advic...\n",
       "..                                                 ...                                                ...\n",
       "383  Young adults who increased social media use we...   In this case, it's not unlikely for people to...\n",
       "384  how did scientists decide that proton has a \"p...  Hello! I am a ninth-grade student. My chemistr...\n",
       "385  mRNA Vaccines: What happens to the antigen pre...  Looking at this: [https://www.cdc.gov/coronavi...\n",
       "386  when talking about climate change, why do we n...   Interesting but confusing. Are you able to ex...\n",
       "387  ‘External source’ causes oil tanker blast off ...                                                   \n",
       "\n",
       "[388 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe with only the Post and all comments related to the post \n",
    "train=posts.groupby('Title')['Comments'].apply(' '.join).reset_index()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1607975164805,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "DDrD0dXpsMTD"
   },
   "outputs": [],
   "source": [
    "#Save the dataset \n",
    "#train.to_csv('/content/drive/MyDrive/Datasets_trained/trained_dataset_summarization.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1607975166004,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "sswWCAzbLbeI",
    "outputId": "ae041899-b2fb-4db8-add1-c50735aed6a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" I'd think with oil this cheap and many places throttling down AND the fact they only did what appears to be minor damage to ship that's it's more of a nothing burger other than the potential for more wide spread violence. As an attack it seems ineffective and most of these attacks have not seemed to drive up the price of oil, which suggests to me the costs of the attacks/ability of the attacks to disrupt the supply chain are minimal. We also don't know who is behind each various attack on Saudi oil. I\\n\\nI don't have much faith in either Saudi or Iran, but I don't see these attacks as being effective at much of anything other than annoyance and escalation of military options, which  Iran will probably lose. \\n\\nIf Iran gets themselves bombed they lose a lot more money than Saudi loses from a ship being damaged or oil output going down for a week or two and Saudi is probably well aware of that. I don't see how Iran ever gets anywhere with this strategy. They will have almost no impact, Saudi will rebuild everything they blow up and keep making billions and Iran is likely to get themselves bombed out of the deal.\\n\\nHow is that hitting them where it hurts? \\n\\nI could just as easily be an attack on Iran disgusted as pointlessly small attacks on Saudi thus justifying military action against Iran BECAUSE the attacks themselves are doing nothing and not actually verified to come from Iran.\\n\\nEither way I don't see Iran benefiting from any of this. It gives Saudi more diplomatic power since they become the victim and Saudi loses almost nothing of significant value. And what do you think happens to SA and their oil industry, Dubai, Djibouti, the UAE and all the US military bases and personnel stationed there if Iran is attacked? this atk maybe was weak but others have been huge. i recall one in Feb was it? effected  a disaster for SA and crushed market adaptability. hitting these soft and logistical targets is all win and no loss. SA cant afford to fight like this. and they are the cornerstone of the shady arrangements made round there\""
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Comments.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1607975166825,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "r3fVn_VyV4wj"
   },
   "outputs": [],
   "source": [
    "train['Title']=train['Title'].apply(str)\n",
    "train['Comments']=train['Comments'].apply(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAO2TxMbE1cw"
   },
   "source": [
    "### Lemmatization and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1607975169010,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "VAl5VK9jEsPI"
   },
   "outputs": [],
   "source": [
    "# defining stopwords list from the nltk and adding additional stop words from the elizethan era\n",
    "stopwords_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stopwords_list += list(string.punctuation)\n",
    "\n",
    "stopwords_list+=[\" \", \"  \", \"#\", \",\", \"|\", \"-\", \"‘\", \"’\", \";\", \"(\", \")\", \".\", \":\", \"¿\", \"?\", '“', \"/\",\n",
    "    '”', '\"', \"'\", \"%\", \"•\", \"«\", \"»\",\"/n\",\"’s\",\"n't\",\"\\n\\n'\",\"'re\",\"www\",\"http\",\"n’t\", \"%\", \"•\", \"«\", \"»\", '``', \"''\", \"--\"]\n",
    "\n",
    "stopwords_list +=  ['http', 'com', 'www', 'askscience'] + web_punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "executionInfo": {
     "elapsed": 14149,
     "status": "ok",
     "timestamp": 1607976070249,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "uqoovDrcE37r",
    "outputId": "c5e31236-1f50-4136-f3e0-8b48f83b8fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (388, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>tokens</th>\n",
       "      <th>simple_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"an eye for an ai: optic device mimics human r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'external source' causes oil tanker blast off ...</td>\n",
       "      <td>i'd think with oil this cheap and many places...</td>\n",
       "      <td>[i, 'd, think, with, oil, this, cheap, and, ma...</td>\n",
       "      <td>'d think oil cheap many place throttling fact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'new variant' of coronavirus identified - bbc</td>\n",
       "      <td>i don’t know much about this subject.\\n\\nbut ...</td>\n",
       "      <td>[i, don, ’, t, know, much, about, this, subjec...</td>\n",
       "      <td>know much subject post sound well informed **r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'new variant' of coronavirus identified - hancock</td>\n",
       "      <td>oh hey, look another copy and paste reply or ...</td>\n",
       "      <td>[oh, hey, ,, look, another, copy, and, paste, ...</td>\n",
       "      <td>oh hey look another copy paste reply bot x200b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'new variant' of coronavirus identified in uk,...</td>\n",
       "      <td>*a* vaccine\\n\\n&gt;and the latest clinical advic...</td>\n",
       "      <td>[*a*, vaccine, &gt;, and, the, latest, clinical, ...</td>\n",
       "      <td>*a* vaccine latest clinical advice 's highly u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  ...                                        simple_text\n",
       "0  \"an eye for an ai: optic device mimics human r...  ...                                                   \n",
       "1  'external source' causes oil tanker blast off ...  ...  'd think oil cheap many place throttling fact ...\n",
       "2      'new variant' of coronavirus identified - bbc  ...  know much subject post sound well informed **r...\n",
       "3  'new variant' of coronavirus identified - hancock  ...  oh hey look another copy paste reply bot x200b...\n",
       "4  'new variant' of coronavirus identified in uk,...  ...  *a* vaccine latest clinical advice 's highly u...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase + formating \n",
    "\n",
    "train['Comments'] = train.Comments.str.lower().str.replace('  ',' ').str.replace('/n','/n ')\n",
    "train['Title'] = train.Title.str.lower().str.replace('  ',' ').str.replace('/n','/n ')\n",
    "\n",
    "#In the subreddit_corpus data, replace any nan with other\n",
    "train['Title'].replace(np.nan,'Other',inplace = True)\n",
    "train['Comments'].replace(np.nan,'Other',inplace = True)\n",
    " \n",
    "# remove links\n",
    "#train['Comments'] = train['Comments'].replace(to_replace=r'^https?:\\/\\/.*[\\r\\n]*',value='',regex=True)\n",
    "train['Comments'] = train['Comments'].replace(to_replace=r'https?:\\/\\/.*[\\r\\n]*',value='',regex=True)\n",
    "#train['Comments'] = re.sub(r'http\\S+\\s+', '', train['Comments'])\n",
    "\n",
    "# Extract word tokens\n",
    "train['tokens'] =train.Comments.map(nltk.tokenize.word_tokenize)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "train['tokens'] = train.tokens.map(lambda x: [lemmatizer.lemmatize(i) for i in x])\n",
    "\n",
    "# Remove stop words\n",
    "def simplify(tokens):\n",
    "    simple_text = ''\n",
    "    for i in tokens:\n",
    "        if i not in stopwords_list: #removing stopwords\n",
    "            if i not in string.punctuation: #removing punctuation\n",
    "                simple_text = simple_text + i + ' '\n",
    "    return str(simple_text)\n",
    "\n",
    "train['simple_text'] = train.tokens.map(simplify)\n",
    "\n",
    "print(\"Shape:\",train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oS1HjGSXQym"
   },
   "source": [
    "## Summary of the algorithm:\n",
    "\n",
    "\n",
    "1.   We clean the comments by removing all extra whitespaces.\n",
    "2.   Tokenize the comment into words and score each word based on its frequency and capitalization. Reduce the score if the token is a digit. \n",
    "3.   Split the comment into separate sentences and score each sentence. Sentences with words with a higher word score will be ranked higher. \n",
    "4.   Return top ranked words and sentences in chronological order. \n",
    "\n",
    "Spacy: Spacy is a natural language processing (NLP) library for Python designed to have fast performance, and with word embedding models built in. We use spacy to access sentences within each comment and named entities within the comment. \n",
    "Entities are the words or groups of words that represent information about common things such as persons, locations, organizations, etc. These entities have proper names.\n",
    "\n",
    "The following Code Sample has been used to implement the code: \n",
    "https://github.com/PhantomInsights/summarizer/blob/master/summary.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 1608,
     "status": "ok",
     "timestamp": 1607976083876,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "xeIE2PWHSuls"
   },
   "outputs": [],
   "source": [
    "#Loading spaCy language model\n",
    "NLP = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 1036,
     "status": "ok",
     "timestamp": 1607976083878,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "58P5CetbTitM"
   },
   "outputs": [],
   "source": [
    "def clean_article(article_text):\n",
    "    \"\"\"Cleans and reformats the article text by removing whitespaces.\n",
    "       Returns a string\n",
    "    \"\"\"\n",
    "\n",
    "    # We divide the script into lines, this is to remove unnecessary whitespaces.\n",
    "    lines_list = list()\n",
    "\n",
    "    for line in article_text.split(\"\\n\"):\n",
    "\n",
    "        # Leading and trailing whitespaces are removed\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        # If the line is too short we ignore it.\n",
    "        if len(stripped_line) >= LINE_LENGTH_THRESHOLD:\n",
    "            lines_list.append(stripped_line)\n",
    "\n",
    "    # Join different lines by adding just a whitespace.\n",
    "    return \"   \".join(lines_list)\n",
    "\n",
    "\n",
    "def get_top_words(scored_words):\n",
    "    \"\"\"Gets the top scored words from the prepared article.\n",
    "      Returns an ordered list with the top words.\n",
    "    \"\"\"\n",
    "\n",
    "    top_words = list()\n",
    "\n",
    "    for word, score in scored_words.most_common():\n",
    "\n",
    "        add_to_list = True\n",
    "\n",
    "        # We avoid duplicates by checking if the word already is in the top_words list.\n",
    "        if word.upper() not in [item.upper() for item in top_words]:\n",
    "\n",
    "            # Sometimes we have the same word but in plural form, we skip the word when that happens.\n",
    "            for item in top_words:\n",
    "                if word.upper() in item.upper() or item.upper() in word.upper():\n",
    "                    add_to_list = False\n",
    "\n",
    "            if add_to_list:\n",
    "                top_words.append(word)\n",
    "\n",
    "    return top_words[0:NUMBER_OF_TOP_WORDS]\n",
    "\n",
    "\n",
    "def get_top_sentences(article_sentences, scored_words):\n",
    "    \"\"\"Gets the top scored sentences from the cleaned article.\n",
    "       Returns a list of ordered list with the top sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    scored_sentences = list()\n",
    "\n",
    "    #Enumerate the sentences to the format (index,sentence)\n",
    "    for index, sent in enumerate(article_sentences):\n",
    "\n",
    "        # Remove any duplicated sentences and calculate the score of the sentence:\n",
    "        if sent.text not in [sent for score, index, sent in scored_sentences]:\n",
    "            scored_sentences.append([score_line(sent, scored_words), index, sent.text])\n",
    "\n",
    "    top_sentences = list()\n",
    "    counter = 0\n",
    "\n",
    "    #Sort the sentences by the score and pick the top sentences\n",
    "    for score, index, sentence in sorted(scored_sentences, reverse=True):\n",
    "\n",
    "        if counter >= NUMBER_OF_SENTENCES:\n",
    "            break\n",
    "\n",
    "        # When the article is too small the sentences maybe empty.\n",
    "        if len(sentence) >= 3:\n",
    "\n",
    "            # We clean the sentence and its index so we can sort in chronological order.\n",
    "            top_sentences.append([index, sentence])\n",
    "            counter += 1\n",
    "\n",
    "    return [sentence for index, sentence in sorted(top_sentences)]\n",
    "\n",
    "\n",
    "def score_line(line, scored_words):\n",
    "    \"\"\"Calculates the score of the given line using the word scores.\n",
    "    Parameters\"\n",
    "    ----------\n",
    "    line : spacy.tokens.span.Span\n",
    "        A tokenized sentence from the article.\n",
    "    scored_words : collections.Counter\n",
    "        A Counter containing the article words and their scores.\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The total score of all the words in the sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    # We remove the stop words\n",
    "    cleaned_line = [token.text for token in line if token.lower_ not in stopwords_list]\n",
    "\n",
    "    # We now sum the total number of occurrences for all words.\n",
    "    temp_score = 0\n",
    "\n",
    "    for word in cleaned_line:\n",
    "        temp_score += scored_words[word]\n",
    "\n",
    "    return temp_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1607976088712,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "jag05SSrSzOc"
   },
   "outputs": [],
   "source": [
    "# The minimum number of characters needed for a line to be valid.\n",
    "LINE_LENGTH_THRESHOLD = 150\n",
    "\n",
    "# The number of sentences we need.\n",
    "NUMBER_OF_SENTENCES = 3\n",
    "\n",
    "# The number of top words we need.\n",
    "NUMBER_OF_TOP_WORDS = 5\n",
    "\n",
    "# Multiplier for uppercase and long words.\n",
    "IMPORTANT_WORDS_MULTIPLIER = 2.5\n",
    "\n",
    "\n",
    "def get_summary(article):\n",
    "    \"\"\"Generates the top words and sentences from the article text.\n",
    "    Returns a dict containing the title of the article, top words and the top scored sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Now we prepare the article for scoring.\n",
    "    cleaned_article = clean_article(article)\n",
    "\n",
    "    # We start the NLP process and vectorize the article using Spacy.\n",
    "    doc = NLP(cleaned_article)\n",
    "\n",
    "    #create a list of sentences\n",
    "    article_sentences = [sent for sent in doc.sents]\n",
    "\n",
    "    #tokenising words of the doc\n",
    "    words_of_interest = [token.text for token in doc if token.lower_ not in stopwords_list]\n",
    "\n",
    "    # We use the Counter class to count all words ocurrences.The higher frequency of the word has a higher\n",
    "    scored_words = Counter(words_of_interest)\n",
    "\n",
    "    for word in scored_words:\n",
    "\n",
    "        # We add bonus points to words starting in uppercase and are equal or longer than 4 characters.\n",
    "        if word[0].isupper() and len(word) >= 4:\n",
    "            scored_words[word] *= IMPORTANT_WORDS_MULTIPLIER\n",
    "\n",
    "        # If the word is a number we punish it by settings its points to 0.\n",
    "        if word.isdigit():\n",
    "            scored_words[word] = 0\n",
    "\n",
    "    top_sentences = get_top_sentences(article_sentences, scored_words)\n",
    "    top_sentences_length = sum([len(sentence) for sentence in top_sentences])\n",
    "    #reduction = 100 - (top_sentences_length / len(cleaned_article)) * 100\n",
    "\n",
    "    summary_dict = {\n",
    "        \"top_words\": get_top_words(scored_words),\n",
    "        \"top_sentences\": top_sentences,\n",
    "        #\"reduction\": reduction,\n",
    "        \"article_words\": \" \".join(words_of_interest)\n",
    "    }\n",
    "\n",
    "    return summary_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1607976089334,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "DSOf8MHKXPvC",
    "outputId": "ea6d6e37-6b7b-4fee-bdc4-6692fc39a6fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Comments</th>\n",
       "      <th>tokens</th>\n",
       "      <th>simple_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"an eye for an ai: optic device mimics human r...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'external source' causes oil tanker blast off ...</td>\n",
       "      <td>i'd think with oil this cheap and many places...</td>\n",
       "      <td>[i, 'd, think, with, oil, this, cheap, and, ma...</td>\n",
       "      <td>'d think oil cheap many place throttling fact ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'new variant' of coronavirus identified - bbc</td>\n",
       "      <td>i don’t know much about this subject.\\n\\nbut ...</td>\n",
       "      <td>[i, don, ’, t, know, much, about, this, subjec...</td>\n",
       "      <td>know much subject post sound well informed **r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'new variant' of coronavirus identified - hancock</td>\n",
       "      <td>oh hey, look another copy and paste reply or ...</td>\n",
       "      <td>[oh, hey, ,, look, another, copy, and, paste, ...</td>\n",
       "      <td>oh hey look another copy paste reply bot x200b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'new variant' of coronavirus identified in uk,...</td>\n",
       "      <td>*a* vaccine\\n\\n&gt;and the latest clinical advic...</td>\n",
       "      <td>[*a*, vaccine, &gt;, and, the, latest, clinical, ...</td>\n",
       "      <td>*a* vaccine latest clinical advice 's highly u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  ...                                        simple_text\n",
       "0  \"an eye for an ai: optic device mimics human r...  ...                                                   \n",
       "1  'external source' causes oil tanker blast off ...  ...  'd think oil cheap many place throttling fact ...\n",
       "2      'new variant' of coronavirus identified - bbc  ...  know much subject post sound well informed **r...\n",
       "3  'new variant' of coronavirus identified - hancock  ...  oh hey look another copy paste reply bot x200b...\n",
       "4  'new variant' of coronavirus identified in uk,...  ...  *a* vaccine latest clinical advice 's highly u...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test the model, we try to extract the top 3 sentences from the post titled: \n",
    "### \"people are desperate': california shutdown pushes businesses to breaking point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1607976102699,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "NkAVrH6LRpfz",
    "outputId": "92e1e81f-10a0-453b-99f6-b61d8c898097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'people are desperate': california shutdown pushes businesses to breaking point\n"
     ]
    }
   ],
   "source": [
    "print(train.Title.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1607976106998,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "1TmaTgqMRPIl",
    "outputId": "a4aee644-4684-4c24-9101-1d7a07ccb947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the issue is that there is little federal support for businesses or people disproportionately affected by shutdowns in the us. sucks that an particular industry was affected by a virus more than other industries while you do kinda have a point about it being a food fight, it is more of the republicans fault. the dems have passed multiple bills in the house to extend/expand the cares act and get more support to people and businesses in need. the rs have been fighting it tooth and nail because it helps people more than corporations. the rs also want a giant liability shield for companies so that they cant be sued if they arent following covid regulations like masking/cleaning/distancing. if the corps get that shield then they will start forcing people back to work in unsafe environments making this whole thing worse. the bottom line is\n",
      "\n",
      "they should have been 100 percent shut down\n",
      "\n",
      "but they needed federal aid for employees and owners to do that\n",
      "\n",
      "trump's government fully abandoned us and now we can't blame them for staying open so they can pay bills.\n",
      "\n",
      "i think we can all pretty much agree that the 2.2 trillion could have covered this, with about 16+k per household\n",
      "\n",
      "that would have paid most peoples bills for like 4 months of lockdown\n",
      "\n",
      "but here we are, can't blame anyone for just trying to survive with an absent government restaurants are particularly problematic. \n",
      "\n",
      "nobody wears masks. the wait staff is interacting and physically handling things which have potential droplet spray, and are crossing tables and groups causing cross contamination. people are inside in closed spaces and typically not the best ventilation (although early contact tracing saw people upwind getting sick too because of turbulent air flow). all data and studies show that regardless of your 6 foot distance, with enough time in a space you will end up with viral spread when masks aren’t worn. \n",
      "\n",
      "it makes sense that indoor dining is closed. more sense than stores and shops where there is limited interaction between groups and people are wearing masks and distancing. proper protocol at this point would be call in/online orders for take out only with no contact carside delivery. or no contact delivery to a persons door step. \n",
      " \n",
      "but, that doesn't help the entire restaurant. it keeps the cooks employed, but receptionists would see a reduction in hours, bus and wait staff would see a full reduction. \n",
      " \n",
      "so, those places are still going to be faced with either layoffs or needing some form of government assistance. restaurants are a big spreader. the cdc has done a study on this. \n",
      "\n",
      "we need more federal stimulus to get them through the next six months or so, because they really need to be shut down for indoor dining. two terrible stats from that link:\n",
      "\n",
      "\"data from san francisco’s chamber of commerce [shows up to 85% of bars and restaurants in formerly bustling parts of the city](\" an analysis by the national restaurant association provided to the guardian this week predicted 43% of california restaurants would not survive the crisis.\" this wouldn't have been an issue of the ppp was properly allocated to small businesses who need it. i mean shutting everything down definitely reduces the spread of the virus - huge number of countries have done this and the numbers speak for themselves...it's hard and it sucks but the tax dollars people have paid should be used to support them during difficult times like this. there is no way to eat safely inside a restaurant. you can't wear masks while eating, and it's a respiratory virus. people stopped caring about the time the california government stopped following their own mandates. so if the cause of spread was not businesses, why close businesses that are behaving responsibly and sanitizing / enforcing mask use properly? once your rights are taken away they are not given back. if you truly believe the government has your best interest at heart, perhaps you should talk to an american indian. yep, lots of trumpets living in san fran. that’s probably the problem lol. you didn't read the article, huh? it's mostly about the low income workers who will no longer have jobs when these businesses shut down. it talks a bit about how that will cause them to lose homes and miss meals. read the fucking article.....califorinia has banned outdoor dining in a lot of places imagine being so tone deaf that you can tell people who are being forced into irrecoverable debt by a governor who doesn’t follow his own health policies that they need to stop complaining. \" but as [california](you act like democrats are negotiating in good faith. they are not.\n",
      "\n",
      "pass things that everyone agrees on and lets fight for the rest separately.\n",
      "\n",
      "\n",
      "but, [that won't happen](> pelosi and mcconnell have not yielded ground from their respective $2.2 trillion and $500 billion aid bills. leaders of the democratic-held house and gop-controlled senate have not held formal talks on stimulus since the 2020 election on nov. 3.\n",
      "\n",
      "not yielding ground is the definition of uncompromising. they’re the same party of rich capitalists!\n",
      "\n",
      "they love crashing your businesses, they can buy your assets for pennies on the dollar!\n",
      "\n",
      "which party will tax the billionaires getting even richer while millions lose everything? neither!\n",
      "\n",
      "which party will even pause the bombing of a half dozen countries and military adventurism that costs us billions every day? neither!\n",
      "\n",
      "which party will increase our healthcare infrastructure, establish a national health service so future pandemics can be tested and treated? neither!\n",
      "\n",
      "wake up america! you live in a one party state. the party that serves their rich political donors!\n",
      "\n",
      "this is bought and paid for oligarchy! a secondary and rather nefarious effect of all of this is that it will be small businesses that will be disproportionately affected by all of this. small independent restaurants lack the war chests needed to ride this out that corporations and larger franchise operations have. since the demand for restaurant food is going to bounce back, new restaurants will open to feed the demand, but they will probably be even more chains restaurants than what it replaced. this trend will occur in other businesses as well (health/fitness centers, for example). this exactly, people shit on state government for closing down with no aid when the federal government *had* the ppp plan in which they gave away millions to the trump businesses, the lakers, and many other undeserving corporations and she'll companies. where is the outrage at the complete failure of leadership? the govt is paying plenty of its own employees to sit on their asses at home since mid march. it's not out of the goodness of their hearts though, they just don't know wtf they're doing. no we got $1200 dollars and letter from trump with his ugly signature like he did us a favor. it’s unreal. $1200 goes a lot further in florida or ohio then it does in nyc or la always trumps fault. meanwhile the liberals in power continue to violate the rules they impose. \n",
      "\n",
      "&#x200b;\n",
      "\n",
      "[[people might be willing to drive 20/30 minutes and pay to park to grab dinner somewhere where you can sit down and then go to a club/walk around or go to a show or something but they aren't going to be as likely to make that same drive/pay for parking and then immediately turn around and drive back home to then reheat the food. and this bullshit \"we brought the inside outside\" tent dining. if giant stores like walmart can be open, why smaller places that have far lower foot traffic cannot is ridiculous. i hope you understand that ppp funds were still available for any small business to apply for as late as november. there wasn't a lack of funding for it. just because the lakers, or whoever, got ppp is not a justification for small businesses not getting it. there no way to do many activities 100% safely. however, the question is if restaurants were the primary vector for spread: so far there has not been evidence to that effect.\n",
      "\n",
      "of restaurants become a major vector, then i understand completely shutting them down. in some places bars have been, so i don’t disagree with bars shutting down when that’s been identified. i'll never understand this mentality. why would a politician acting immoral make you want to do the same? the outcome doesn't magically change because someone did something wrong first. i will speak for myself and say that no, i did not stop following government mandates when i heard that the california governor went on a vacation. that's like not wiping your ass because the toilet paper company executive has a bidet well that’s a shitty attitude. just because someone else runs a red light, i’m not going to start running red lights, putting myself and other at risk of an accident. >so if the cause of spread was not businesses\n",
      "\n",
      "don't see anyone saying that...where'd you get that from? feels crazy that this needs to be clarified but gatherings in home and gatherings in work places both have the ability to spread the virus. they tried other measures, people didn’t follow them. they didn’t really leave the state any other options to try and get things under control. damn you are right. they give local restaurants the right to not serve me raw chicken. how dare they. they give you the right to not run red lights. \n",
      "how dare they. they give the right not to rape your mother. how dare they. save your rights for the patriot act. save your rights for the nsa curbstomping any electronic privacy...\n",
      "\n",
      "the government isn't a monolith. it's made up of individuals. it's a bad actor and a good actor. stop equating one bad act to the whole thing/ stop equating one good act to the whole thing. learn to analyze. i realize i've done some false equivalences, but damn, you did one for whole government like it's one person sitting on a throne. \n",
      "\n",
      "its a lifelong process discerning and utilizing critical thought. fucking use it and grow it. \n",
      "\n",
      "this could have been over in a few months... i’m sure cracker barrel is one of the more popular staples of san fransisco dining. also, if you don't believe conspiracy nuts/ anti maskers, etc live there... you're delusional i didn't say \"trumpets\". cracker barrel is a generalization for any restaurant as in freedom to serve shit food that might affect a customer. i live on east coast and used what i know here. san fran is not a unique butterfly. i repeat. the population of san fran or any major city in the usa is not homogeneous in efforts to curtail a pandemic. \n",
      "\n",
      "frequent hornet and indiecomic, get off your plastic, kid-sized rocking horse and that is wrong. because there are red lines that the democrats won't cross. most significant is republicans' wish to give corporations a \"liability shield\" for things they do that might put their employees at risk of contracting covid.\n",
      "\n",
      "it's not about the $2.2 trillion vs. $500 million dollar amounts, it's about whether or not congress will approve a bill that allows corporations to avoid accountability for negligence.\n",
      "\n",
      "[1) no liability for any employer which is absolutely absurd considering so many companies are blatantly putting their employees at risk.\n",
      "\n",
      "2) no direct money for the citizens. you know, the people suffering the most.\n",
      "\n",
      "fuck off with this \"both sides are responsible for the suffering\" crap. republicans are solely responsible for every single family going hungry right now. for every family choosing whether to be healthy or to have a home. for every person gasping for breath as they die away from their family. this is on them.\n",
      "\n",
      "the republican party is a cancer, trump was just a tumor. maybe. it depends on who goes to them. younger folks typically prefer non chain places, especially hole in the wall restaurants. \n",
      " \n",
      "it's older folks who like applebees, chili's, etc.. california also had a small business benefits program that was heavily botched as scammers, whether they were already rich folks or even people from other states, took money meant for small businesses struggling during the pandemic.\n",
      "\n",
      "it was and still is the subject of local news investigation teams. i think they know exactly what they are doing\n",
      "\n",
      "they are killing us. culling the herd trump is in charge... people in charge are responsible for the shit that happens for fuck's sake. that's how it fucking works. bringing up someone else's boneheaded decision doesn't change that. yes it's trumps fault this time\n",
      "\n",
      "but ultimately our government has failed us every single step of the way with their endless bickering and trying to inject policies completely unrelated to financial relief into the bills.\n",
      "\n",
      "they are somehow incapable of just writing a bill about a single issue and addressing it, without creating something to make it partisan i've seen just the opposite actually, can you share the relevant data with the class please? melbourne says otherwise. our patchwork ones weren't sure. if we had actually managed this from a country wide level it'd be a way different story. >news.trust.org/item/2...\n",
      "\n",
      "$16,000 - missed a zero thanks for the link. i’ve seen similar study results and articles several months ago. i understand this really screws restaurant owners, but people can’t just pretend that the problem doesn’t exist or isn’t real. \n",
      "\n",
      "then you get people who think it’s ok to take a risk because it’s their choice. not recognizing they are just going to carry the virus and raise the risk of spread to people like me who are doing as much as possible to keep my family safe (we have some very high risk people). and that by taking that risk, they are making this thing worse and making it take longer. \n",
      "\n",
      "the selfishness is astounding. the number of people who just don’t care enough to even try to understand it frightens me. i know a woman who had all the symptoms of covid but didn’t think she had it and went on a vacation trip with her family. she had a covid test done but didn’t have the results yet. everyone she interacted with is at risk now. the restaurants she attended, the gas stations she stopped at. \n",
      "\n",
      "bottom line is the reason we don’t trust people and the reason things are getting shut down, is because enough people aren’t even trying to do the right thing that it’s raising the risk for everyone by an unacceptable level. yeah food transmission is low which is good. the only problem with outdoor as it gets colder is i’m seeing a lot of restaurants set up a tent that’s not any bigger than their normal seating, with heaters there, and just as full as the indoor dining. \n",
      "\n",
      "when it’s warm i think outdoor dining is great. isn't eat out to help out in the uk blamed for causing the second spike and new lockdowns? i didn’t say they would contract the virus. i don’t know that data. but that’s not what i was talking about. \n",
      "\n",
      "i said they are handling plates, money, drinks, etc and raise the potential for cross contamination. unless the wait staff is completely sanitizing between every table they visit they are raising cross contamination potential (community spread). \n",
      "\n",
      "you need to assume every plate and glass and fork/knife is contaminated. then the wait staff touches it. then they go to another table, and another table. it just raises the risk. and remember this isn’t absolutes, it’s risk. you have holes in the swiss cheese, and these things make the holes bigger.\n",
      "\n",
      "\n",
      "as an aside: when you look at the john hopkins data for just the us, the risk is tremendously higher right now than it was 6-9 months ago. we should be doing tremendously more to fight it now. it doesn’t make sense we are doing less mitigation than we did in march/april when it wasn’t this bad. i'm not the person you're responding to, but it wasn't my thought process that servers who are properly wearing masks, washing hands, etc. are more likely to contract the virus; it's the patrons who are eating indoors, especially in inadequate-airflow situations, who are more likely to contract it because of other patrons.\n",
      "\n",
      "there was a report a while back from a coffee shop in south korea where workers all wore kn94 masks (and conducted appropriate cleaning), served covid-19-positive patrons (learned after the fact), and none of the workers contracted the virus. because people need to buy groceries? grocery stores are essential. restaurants are a luxury. people can also wear a mask while shopping for groceries, and the fact that people are moving around makes spread less likely. ah yes large, ventilated stores where you are required to wear a mask totally compares to small, concentrated stores where you can’t wear a mask. it wasn't necessarily a lack of funding as much as a complete failure from higher leadership. note: not agreeing with the following, just providing an explanation of the mentality.\n",
      "\n",
      "it sends a message that the policy isn't actually necessary since if it was the politicians who were advocating so loudly for it wouldn't be willing to flagrantly ignore it. you really can't figure it out?\n",
      "\n",
      "people are scared and desperate (in a lot of cases) and those people don't act rationally.\n",
      "\n",
      "from their point of view, the government has closed tons of businesses, put millions out of work. and they've done so while providing essentially zero support to the workers or business owners.\n",
      "\n",
      "for business owners: they are looking at losing basically everything they've put their blood, sweat and tears into creating, possibly over decades when they lose their business because they have been forbidden from making money but still have bills to pay. they may even be losing their home and any chance of retiring. some may bounce back, many won't.\n",
      "\n",
      "for employees: they are looking at losing everything as well, their home (or apartment), they are wondering how they are going to find food, where they are going to get shelter, etc. they, especially people who have been paying into a home for years or decades, are going to lose everything and will be struggling with the financial cost of this for years or decades.\n",
      "\n",
      "you're asking them to ruin themselves financially (and all the negative physical and mental health effects that come with that) for years or decades to avoid what for many of them may be a very very small chance of death or serious harm.\n",
      "\n",
      "meanwhile, you have the very politicians who are telling them to make this sacrifice and often berating them if they aren't following guidelines, the same politicians who have a constant paycheck, who are not looking at losing their livelihood, who are seeing all the data from the experts, publicly ignoring their own orders.\n",
      "\n",
      "what conclusion would you draw when you're desperate there? clearly, it's not that dangerous because the people who have the most knowledge on it to make the guidelines don't really think it's serious enough to follow.\n",
      "\n",
      "or, they know how serious it is but are desperate and think the slight possibility of serious complications for themselves is a far better risk than the certain hardships they'll endure by complying.\n",
      "\n",
      "desperate people, make desperate decisions. because it makes you suspect ulterior motives. they are supposed to have all the \"inside\" info so people pay attention to what they do. for a well-adjusted, critical thinking adult sure. but how many people in this country do you think actually fit that ticket? how many more do you think do not? maybe because the a politician was full of shit in the 1st place? political leaders should be worried about getting sick and dropping dead, not bad pr if they get caught.\n",
      "\n",
      "that political leaders are blatantly ignoring their own restrictions means they don't believe the virus is actually as dangerous as they're telling the rest of us.\n",
      "\n",
      "they have access to all of the best information, and they make the decision to have dinner in a crowded area, or get their hair done because they're not afraid of the danger. can you point me to the studies that do? packed bars - yes. two dozen people seated and spaced appropriately? i’d like to at least have some evidence before destroying livelihoods. but if the restaurants were not the root cause for major spread, why inflict damage on people’s livelihoods? \n",
      "\n",
      "your statement pretty much sums up how many feel: that some of the restrictions are more about punishing the public than trying to reduce spread. no it isn't, if you take measures and they dont work, you take further measures.\n",
      "\n",
      "if people are still getting sick from out door dining then guess what, out door dining gets shut down. it doesn't have to be the same large chains; it could be other, hipper chains too. i'm sure it will be handled smoothly and quickly...... maybe the governor should stop breaking his own restrictions, and give this money to his citizens. \n",
      "\n",
      "also, you realize trump cannot write bills right? he's also gone in a few days, pretty much powerless at this point. yup. just like the weed bill that passed last week. can't just legalize weed, nope, gotta at some social justice in there and cloud the issue. go look at state by state case data for the past two weeks and then systematically, just from the data, tell me if a state was using lockdowns or not. you're going to have a hard time. ah! yes, 16k is 4 months easy, you won't even need to get rid of netflix why don’t we close grocery stores then? we saw a spike during the summer here even though all dining at restaurants was banned. then we open outdoor dining as cases were falling an continued to fall, right up to halloween and the election. \n",
      "\n",
      "basically we haven’t even tried to learn what does and does not work in nine months. we are back to blanket bans of everything ... except things that are uncomfortable. we shouldn’t pretend we are proceeding scientifically if we didn’t even try to figure anything out. we’re talking outdoors in ca. especially northern ca. indoor dining briefly was allowed in the past month at 25% capacity, but had been prohibited since march. again, anecdotal evidence from nine months and an ocean away doesn’t address what’s going on now. \n",
      "\n",
      "i don’t mean to harsh on you. i’m frustrated with our local and state governments lame efforts and strategy. too bad they don't and walmart isn't gonna enforce it it's really not a failure. the media and uninformed people believe it to be so, but largely it was successful which is why congress has a second round of it in the upcoming stimulus. what's the theory here? why aren't they following the rules? also, the virus doesn’t kill everybody equally, so a spreader could be fine while he or she spreads death to strangers.\n",
      "\n",
      "the epicenter will never feel the consequence of his or her actions. those folks were already not following any sort of guidelines. no amount of \"librul elitist politicians\" following the guidelines is going to change their minds. in what way? not sure what you're asking for....a study to show that viruses can be transmitted in a work place...because there has been a hell of a lot of news stories of corona spreading through out work places in the last 12 months? because they still cause spread. it’s like a last resort to control the spread. there were better options but people didn’t want to comply. ...and it hasn’t. even government officials are shocked how botched the entire affair has been because of the backed-up system and the rampant mistakes. governors breaking their own covid restrictions isnt an issue though with the costs of businesses.\n",
      "\n",
      "everyone left and right were breaking guidelines. even the federal government with trump who was forcing events.\n",
      "\n",
      "that wad inevitable.\n",
      "\n",
      "giving money to citizens is valid but thats a breakdown at the federal and local level.\n",
      "\n",
      "i really dont give a shit of newsom broke his rules as long as he managed things well. stop with the whataboutism. \n",
      "\n",
      "and yes, i realize that, but he has shown no leadership regardless. had he done is best to unify and get things passed and provided guidance then it would be one thing... but he's shown solidly the kind of worthless imbecile he is. i mean, did you see his live press conferences in the spring?? he was literally *incomprehensible*, not to mention the lies he has spread about the virus and his lack of consistent messaging about safety precautions. what i'm getting is \"i don't have the data, but i'm sure it's out there somewhere\". i'm asking you to share that data with us.\n",
      "\n",
      "then we can all agree and say \"yea what i'm looking at agrees with you\"\n",
      "\n",
      "but you don't actually have any links to share.\n",
      "\n",
      "on top of this, lockdowns in other countries meant way more than they did here.\n",
      "\n",
      "half the states that went into \"lockdown\" didn't enforce anything and just let businesses decide for themselves if they were essential or not you joke, but keeping netflix is actually great in a pandemic since it's an easy and cheap activity that keeps you indoors. the last thing you want, is people to have nothing to do at home, because that encourages them to go out and infect others. \n",
      " \n",
      "video games, television, ebooks, music, and so on are the activities that really need promoted right now. grocery stores were open as essential services. \n",
      "\n",
      "additionally grocery stores can require masks, have been minimizing people in the store (at least in my state), control flow of traffic to minimize interactions, and put measures in place to minimize interaction with the cashiers. many places also have specific high risk hours for elderly and other high risk people. all reducing risk. \n",
      "\n",
      "we could choose to close grocery stores if things got dramatically worse and then move to curbside pickup only (which i’m doing anyway as much as i can). \n",
      "\n",
      "by the way these “blanket bans” are based on planning, historical data, medical professionals and governments working together, and based on both reducing risk and managing the impact of that risk. \n",
      "\n",
      "anybody who says a grocery store and the risk there is similar to a restaurant is likely misinformed, or not evaluating all the data. i also want to point out that most humans are not trained or well suited for risk assessment, mitigation, and management. that’s part of the reason we use a representative government in this country and not a direct one. so the people who do get specialized training and expertise can make those decisions on behalf of the people to do exactly what their job is, manage the public health and well-being.\n",
      "\n",
      "question for you? what are the potential spread vectors for a grocery store and a restaurant. how are they mitigated? what risks remain? \n",
      "\n",
      "final comment: at the end of the day the goal is to reduce the r factor. the government could blanket lock us all in our houses. or they could limit things in such a way that the average r drops low enough (meaning some moderate risk things may remain open if they are important to maintain, and some moderate risk stuff may be closed). this is all at a macro level and the key variables are exponential ones. not linear variables that you are discussing. it's about proper adherence to what we know that reduces the spread of the virus--proper usage of masks works. proper hygiene works if everyone is following it.\n",
      "\n",
      "people here are not adequately following what is known to reduce the spread. cases go up, icu beds reach capacity and more people die.\n",
      "\n",
      "you can ask people to wear masks, do all the right things, etc., but short of a policing method, what's left? draconian restrictions on businesses where people congregate so that people don't congregate as much and the spread can be reduced.\n",
      "\n",
      "look, you're preaching to the choir. we started a business in the bay area 5 months prior to when the pandemic began in the us. we haven't been able to reasonably function since march. we haven't even made rent a single month since. we did not quality for ppp monies. we were not offered any zero-interest loans by any bank we could find because we didn't have sufficient revenue in 2019 since we were only open for 2 months last year. \n",
      "\n",
      "the first active failing in this is the country leadership knowing how deadly this was, but not wanting to alarm anyone so that the economic numbers didn't tank in their election year. the second failing is turning this into a political discourse platform rather than recognizing what everyone needs to do to help. the third failing is providing zero practical financial support from the bottom up. the top-down earlier in the year was nothing more than a money grab for the wealthy because that's all they care about.\n",
      "\n",
      "so what can be done to reduce the spread and reduce the deaths in locally? the reason these ridiculous restrictions happen is because the general public are not following what we know reduces the spread, and you have more people with the virus spreading it. being outside only reduces the chance of the virus spreading, but if there are more people even outdoors congregating around the same place that have it, the risk of contracting it is still higher. and you're hoping that the people--some are the same people that aren't doing the correct things in other aspects of their daily lives--follow guidelines.\n",
      "\n",
      "the reason for all of these restrictions is because the icu beds are near capacity in many places and the only thing that can be requested is shutting down known public congregation.\n",
      "\n",
      "you can be mad at the governor or the local leaders, but that isn't where the failure is happening. everyone wears a mask where i live. that is on your local leaders and leo to enforce it. lmao! then why are so many small businesses shuttering while millions went to trump and co? i can't speak to their motives (individually), but i'll chime in on what i know. i work in critical care. when this first started we had meetings and we all knew how this would play out.\n",
      "\n",
      "but, we also know our society (as a group) are little kids and can't follow directions or bother to really understand an issue.\n",
      "\n",
      "covid is going to run it's course, vaccines will help (eventually) and it will be part of the \"permanent\" disease landscape just like the flu and common cold.\n",
      "\n",
      "every arm flailing rule and action has been done because if we just told people who were at risk (old, obese, poor health) that they and their immediate people needed to take actions to protect themselves but the rest of society had to suck it up and carry on they would have bitched and whined about how it was \"unfair\" to them and them alone.\n",
      "\n",
      "covid is piggy backing on the terrible habits we (as a society) have embraced for generations due to the advance of modern medicine.\n",
      "\n",
      "we warehouse old people for years if not decades and keep them alive by artificial means while more or less ignoring them unless we feel we can sue when then finally succumb to bedsores (and general overwhelming infection).\n",
      "\n",
      "we waddle around 100+ pounds overweight with tons of associated medical issues due to it even though the medical profession has been yelling at the population for generations to stop that shit, the meds your taking to control it are a band aide and it will kill you.\n",
      "\n",
      "we eat garbage and take in tons of shit (drugs) that are bad for you in the long term.\n",
      "\n",
      "then something like covid comes along and starts kicking all these folks who were 9 toes in the grave down into the hole and the populace screams \"do something!!!!\".\n",
      "\n",
      "we've been told to do something for generations. we've ignored the social issue to warehousing old folks for decades.\n",
      "\n",
      "/that's pretty much it, and its gone over pretty much like we (in healthcare) thought it would. note: not agreeing with the following, just providing an explanation of the mentality.\n",
      "\n",
      "one of the most \"reasonable\" explanations is that the rules are there as a way to crush the politicians' business friends' competition and leave openings for their friends to come in and expand into the now-vacated space. see the way amazon, walmart, and the other mega-retailers have had absolutely *booming* business while their smaller competition are struggling for what can be viewed as evidence of this. the politicians refusal to follow the rules just \"proves\" that the issue is manufactured for the already-stated reason. which makes their poor decision all the more worse. so it was run about as well as any other california government program? trump has shown no leadership; agreed.\n",
      "\n",
      "some governors dropped the ball *after* trump dropped the ball.\n",
      "\n",
      "you can blame trump if you want, but that doesn't erase other people's actions that were layered on top. his conferences are too cringe for me to watch. so no. but this thread is addressing small businesses that are being hammered by shutdowns and needing money. if the solution is give em some more taxpayer money, congress will have to do that. what you got was \"the data doesn't support the argument\". it seems like the one saying the data does support the argument should provide the data. what i'm getting is \"i have the ability to to learn more but in the process possibly invalidate my own opinion, but am choosing not to because i don't like being wrong\" unless you have no job.\n",
      "\n",
      "if you have no job, you should be consuming almost no costly entertainment at all, and allocating your time and money towards becoming productive.\n",
      "\n",
      "ideally, your production is your entertainment. all good questions but at this point we should have data. grocery clerk come into proximity with many more customers than waiters. we can hadwave all day. there should be data on each type of employee at this point. if we don’t even have data, that is just incompetent. i guess i don't understand how this would have solved the issue of space. \n",
      "\n",
      "[understanding that people don't really follow rules, wouldn't having less rules have just meant running out of icu beds much quicker?\n",
      "\n",
      "the rest of your comment makes sense. we likely won't reverse the course on obesity, so it's all just going to keep getting worse. just share the data and make your stance viable.\n",
      "\n",
      "you made the claim, we don't have the burden of having to dig up information that you seem to be aware of already, to validate a claim that you made.\n",
      "\n",
      "just share the information share your data\n"
     ]
    }
   ],
   "source": [
    "#Display the original comments under this post\n",
    "print(train.Comments.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1972,
     "status": "ok",
     "timestamp": 1607976205736,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "2VjlRiZGNqnc",
    "outputId": "bf971ed1-054f-4699-d810-899e692d70f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_words': \"issue little federal support businesses people disproportionately affected shutdowns us sucks particular industry affected virus industries kinda point food fight republicans fault dems passed multiple bills house extend expand cares act get support people businesses need rs fighting tooth nail helps people corporations rs also want giant liability shield companies ca nt sued nt following covid regulations like masking cleaning distancing corps get shield start forcing people back work unsafe environments making whole thing worse bottom line nobody wears masks wait staff interacting physically handling things potential droplet spray crossing tables groups causing cross contamination people inside closed spaces typically best ventilation although early contact tracing saw people upwind getting sick turbulent air flow data studies show regardless 6 foot distance enough time space end viral spread masks worn makes sense indoor dining closed sense stores shops limited interaction groups people wearing masks distancing proper protocol point would call online orders take contact carside delivery contact delivery persons door step help entire restaurant keeps cooks employed receptionists would see reduction hours bus wait staff would see full reduction places still going faced either layoffs needing form government assistance restaurants big spreader cdc done study need federal stimulus get next six months really need shut indoor dining two terrible stats link data san francisco chamber commerce shows 85 bars restaurants formerly bustling parts city analysis national restaurant association provided guardian week predicted 43 california restaurants would survive crisis would issue ppp properly allocated small businesses need mean shutting everything definitely reduces spread virus huge number countries done numbers speak ... 's hard sucks tax dollars people paid used support difficult times like way eat safely inside restaurant ca wear masks eating 's respiratory virus people stopped caring time california government stopped following mandates cause spread businesses close businesses behaving responsibly sanitizing enforcing mask use properly rights taken away given back truly believe government best interest heart perhaps talk american indian yep lots trumpets living san fran probably problem lol read article huh 's mostly low income workers longer jobs businesses shut talks bit cause lose homes miss meals read fucking article ..... califorinia banned outdoor dining lot places imagine tone deaf tell people forced irrecoverable debt governor follow health policies need stop complaining california](you act like democrats negotiating good faith wo happen pelosi mcconnell yielded ground respective 2.2 trillion 500 billion aid bills leaders democratic held house gop controlled senate held formal talks stimulus since 2020 election nov 3 bought paid oligarchy secondary rather nefarious effect small businesses disproportionately affected small independent restaurants lack war chests needed ride corporations larger franchise operations since demand restaurant food going bounce back new restaurants open feed demand probably even chains restaurants replaced trend occur businesses well health fitness centers example exactly people shit state government closing aid federal government ppp plan gave away millions trump businesses lakers many undeserving corporations 'll companies outrage complete failure leadership govt paying plenty employees sit asses home since mid march 's goodness hearts though know wtf got 1200 dollars letter trump ugly signature like us favor unreal 1200 goes lot florida ohio nyc la always trumps fault meanwhile liberals power continue violate rules impose people might willing drive 20/30 minutes pay park grab dinner somewhere sit go club walk around go show something going likely make drive pay parking immediately turn around drive back home reheat food bullshit brought inside outside tent dining giant stores like walmart open smaller places far lower foot traffic ridiculous hope understand ppp funds still available small business apply late november lack funding lakers whoever got ppp justification small businesses getting way many activities 100 safely however question restaurants primary vector spread far evidence effect restaurants become major vector understand completely shutting places bars disagree bars shutting identified 'll never understand mentality would politician acting immoral make want outcome magically change someone something wrong first speak say stop following government mandates heard california governor went vacation 's like wiping ass toilet paper company executive bidet well shitty attitude someone else runs red light ’m going start running red lights putting risk accident cause spread businesses see anyone saying ... where'd get feels crazy needs clarified gatherings home gatherings work places ability spread virus tried measures people follow really leave state options try get things control damn right give local restaurants right serve raw chicken dare give right run red lights dare give right rape mother dare save rights patriot act save rights nsa curbstomping electronic privacy ... government monolith 's made individuals 's bad actor good actor stop equating one bad act whole thing/ stop equating one good act whole thing learn analyze realize 've done false equivalences damn one whole government like 's one person sitting throne could months ... ’m sure cracker barrel one popular staples san fransisco dining also believe conspiracy nuts/ anti maskers etc live ... delusional say trumpets cracker barrel generalization restaurant freedom serve shit food might affect customer live east coast used know san fran unique butterfly repeat population san fran major city usa homogeneous efforts curtail pandemic frequent hornet indiecomic get plastic kid sized rocking horse wrong red lines democrats wo cross significant republicans wish give corporations liability shield things might put employees risk contracting covid 's 2.2 trillion vs. 500 million dollar amounts 's whether congress approve bill allows corporations avoid accountability negligence fuck sides responsible suffering crap republicans solely responsible every single family going hungry right every family choosing whether healthy home every person gasping breath die away family republican party cancer trump tumor maybe depends goes younger folks typically prefer non chain places especially hole wall restaurants 's older folks like applebees chili 's etc .. california also small business benefits program heavily botched scammers whether already rich folks even people states took money meant small businesses struggling pandemic killing us culling herd trump charge ... people charge responsible shit happens fuck 's sake 's fucking works bringing someone else 's boneheaded decision change yes 's trumps fault time ultimately government failed us every single step way endless bickering trying inject policies completely unrelated financial relief bills somehow incapable writing bill single issue addressing without creating something make partisan 've seen opposite actually share relevant data class please melbourne says otherwise patchwork ones sure actually managed country wide level 'd way different story news.trust.org/item/2 ... 16,000 missed zero thanks link ’ve seen similar study results articles several months ago understand really screws restaurant owners people ca pretend problem exist real get people think ok take risk choice recognizing going carry virus raise risk spread people like much possible keep family safe high risk people taking risk making thing worse making take longer selfishness astounding number people care enough even try understand frightens know woman symptoms covid think went vacation trip family covid test done results yet everyone interacted risk restaurants attended gas stations stopped bottom line reason trust people reason things getting shut enough people even trying right thing raising risk everyone unacceptable level yeah food transmission low good problem outdoor gets colder ’m seeing lot restaurants set tent bigger normal seating heaters full indoor dining warm think outdoor dining great eat help uk blamed causing second spike new lockdowns say would contract virus know data talking said handling plates money drinks etc raise potential cross contamination unless wait staff completely sanitizing every table visit raising cross contamination potential community spread need assume every plate glass fork knife contaminated wait staff touches go another table another table raises risk remember absolutes risk holes swiss cheese things make holes bigger aside look john hopkins data us risk tremendously higher right 6 9 months ago tremendously fight make sense less mitigation march april bad 'm person responding thought process servers properly wearing masks washing hands etc likely contract virus 's patrons eating indoors especially inadequate airflow situations likely contract patrons report back coffee shop south korea workers wore kn94 masks conducted appropriate cleaning served covid-19-positive patrons learned fact none workers contracted virus people need buy groceries grocery stores essential restaurants luxury people also wear mask shopping groceries fact people moving around makes spread less likely ah yes large ventilated stores required wear mask totally compares small concentrated stores ca wear mask necessarily lack funding much complete failure higher leadership note agreeing following providing explanation mentality sends message policy actually necessary since politicians advocating loudly would willing flagrantly ignore really ca figure point view government closed tons businesses put millions work 've done providing essentially zero support workers business owners business owners looking losing basically everything 've put blood sweat tears creating possibly decades lose business forbidden making money still bills pay may even losing home chance retiring may bounce back many wo employees looking losing everything well home apartment wondering going find food going get shelter etc especially people paying home years decades going lose everything struggling financial cost years decades asking ruin financially negative physical mental health effects come years decades avoid many may small chance death serious harm meanwhile politicians telling make sacrifice often berating following guidelines politicians constant paycheck looking losing livelihood seeing data experts publicly ignoring orders conclusion would draw desperate clearly 's dangerous people knowledge make guidelines really think 's serious enough follow know serious desperate think slight possibility serious complications far better risk certain hardships 'll endure complying desperate people make desperate decisions makes suspect ulterior motives supposed inside info people pay attention well adjusted critical thinking adult sure many people country think actually fit ticket many think maybe politician full shit 1st place political leaders worried getting sick dropping dead bad pr get caught political leaders blatantly ignoring restrictions means believe virus actually dangerous telling rest us access best information make decision dinner crowded area get hair done afraid danger point studies packed bars yes two dozen people seated spaced appropriately ’d like least evidence destroying livelihoods restaurants root cause major spread inflict damage people livelihoods statement pretty much sums many feel restrictions punishing public trying reduce spread take measures nt work take measures people still getting sick door dining guess door dining gets shut large chains could hipper chains 'm sure handled smoothly quickly ...... maybe governor stop breaking restrictions give money citizens also realize trump write bills right 's also gone days pretty much powerless point yup like weed bill passed last week ca legalize weed nope got ta social justice cloud issue go look state state case data past two weeks systematically data tell state using lockdowns going hard time ah yes 16k 4 months easy wo even need get rid netflix close grocery stores saw spike summer even though dining restaurants banned open outdoor dining cases falling continued fall right halloween election basically even tried learn work nine months back blanket bans everything ... except things uncomfortable pretend proceeding scientifically even try figure anything ’re talking outdoors ca especially northern ca indoor dining briefly allowed past month 25 capacity prohibited since march anecdotal evidence nine months ocean away address going mean harsh ’m frustrated local state governments lame efforts strategy bad walmart gon na enforce 's really failure media uninformed people believe largely successful congress second round upcoming stimulus 's theory following rules also virus kill everybody equally spreader could fine spreads death strangers epicenter never feel consequence actions folks already following sort guidelines amount librul elitist politicians following guidelines going change minds way sure asking .... study show viruses transmitted work place ... hell lot news stories corona spreading work places last 12 months still cause spread like last resort control spread better options people want comply ... even government officials shocked botched entire affair backed system rampant mistakes governors breaking covid restrictions nt issue though costs businesses yes realize shown leadership regardless done best unify get things passed provided guidance would one thing ... 's shown solidly kind worthless imbecile mean see live press conferences spring literally incomprehensible mention lies spread virus lack consistent messaging safety precautions 'm getting data 'm sure 's somewhere 'm asking share data us half states went lockdown enforce anything let businesses decide essential joke keeping netflix actually great pandemic since 's easy cheap activity keeps indoors last thing want people nothing home encourages go infect others video games television ebooks music activities really need promoted right grocery stores open essential services additionally grocery stores require masks minimizing people store least state control flow traffic minimize interactions put measures place minimize interaction cashiers many places also specific high risk hours elderly high risk people reducing risk could choose close grocery stores things got dramatically worse move curbside pickup ’m anyway much way blanket bans based planning historical data medical professionals governments working together based reducing risk managing impact risk anybody says grocery store risk similar restaurant likely misinformed evaluating data also want point humans trained well suited risk assessment mitigation management part reason use representative government country direct one people get specialized training expertise make decisions behalf people exactly job manage public health well final comment end day goal reduce r factor government could blanket lock us houses could limit things way average r drops low enough meaning moderate risk things may remain open important maintain moderate risk stuff may closed macro level key variables exponential ones linear variables discussing 's proper adherence know reduces spread virus proper usage masks works proper hygiene works everyone following ask people wear masks right things etc short policing method 's left draconian restrictions businesses people congregate people congregate much spread reduced look preaching choir started business bay area 5 months prior pandemic began us able reasonably function since march even made rent single month since quality ppp monies offered zero interest loans bank could find sufficient revenue 2019 since open 2 months last year first active failing country leadership knowing deadly wanting alarm anyone economic numbers tank election year second failing turning political discourse platform rather recognizing everyone needs help third failing providing zero practical financial support bottom top earlier year nothing money grab wealthy 's care done reduce spread reduce deaths locally reason ridiculous restrictions happen general public following know reduces spread people virus spreading outside reduces chance virus spreading people even outdoors congregating around place risk contracting still higher hoping people people correct things aspects daily lives follow guidelines reason restrictions icu beds near capacity many places thing requested shutting known public congregation mad governor local leaders failure happening everyone wears mask live local leaders leo enforce lmao many small businesses shuttering millions went trump co ca speak motives individually 'll chime know work critical care first started meetings knew would play covid going run 's course vaccines help eventually part permanent disease landscape like flu common cold every arm flailing rule action done told people risk old obese poor health immediate people needed take actions protect rest society suck carry would bitched whined unfair alone warehouse old people years decades keep alive artificial means less ignoring unless feel sue finally succumb bedsores general overwhelming infection waddle around 100 pounds overweight tons associated medical issues due even though medical profession yelling population generations stop shit meds taking control band aide kill something like covid comes along starts kicking folks 9 toes grave hole populace screams something /that 's pretty much gone pretty much like healthcare thought would note agreeing following providing explanation mentality one reasonable explanations rules way crush politicians business friends competition leave openings friends come expand vacated space see way amazon walmart mega retailers absolutely booming business smaller competition struggling viewed evidence politicians refusal follow rules proves issue manufactured already stated reason makes poor decision worse run well california government program trump shown leadership agreed blame trump want erase people 's actions layered top conferences cringe watch thread addressing small businesses hammered shutdowns needing money solution give em taxpayer money congress got data support argument seems like one saying data support argument provide data 'm getting ability learn process possibly invalidate opinion choosing like wrong unless job ideally production entertainment good questions point data grocery clerk come proximity many customers waiters hadwave day data type employee point even data incompetent guess understand would solved issue space rest comment makes sense likely wo reverse course obesity 's going keep getting worse share data make stance viable\",\n",
       " 'top_sentences': ['bottom line is the reason we don’t trust people and the reason things are getting shut down, is because enough people aren’t even trying to do the right thing that it’s raising the risk for everyone by an unacceptable level.',\n",
       "  'people can also wear a mask while shopping for groceries, and the fact that people are moving around makes spread less likely.',\n",
       "  'every arm flailing rule and action has been done because if we just told people who were at risk (old, obese, poor health) that they and their immediate people needed to take actions to protect themselves but the rest of society had to suck it up and carry on they would have bitched and whined about how it was \"unfair\" to them and them alone.   '],\n",
       " 'top_words': ['people', \"'s\", 'risk', 'data', 'businesses']}"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(train.Comments.iloc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following output shows the top 3 picked sentences from the entire reddit post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1629,
     "status": "ok",
     "timestamp": 1607976207621,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "zDc12lYfp9wz",
    "outputId": "102a4bd8-6879-49e9-9ded-e9bc593df72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bottom line is the reason we don’t trust people and the reason things are getting shut down, is because enough people aren’t even trying to do the right thing that it’s raising the risk for everyone by an unacceptable level.',\n",
       " 'people can also wear a mask while shopping for groceries, and the fact that people are moving around makes spread less likely.',\n",
       " 'every arm flailing rule and action has been done because if we just told people who were at risk (old, obese, poor health) that they and their immediate people needed to take actions to protect themselves but the rest of society had to suck it up and carry on they would have bitched and whined about how it was \"unfair\" to them and them alone.   ']"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary(train.Comments.iloc[5])['top_sentences']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqYzx_ukhDt1"
   },
   "source": [
    "# Module 2: Cosine Similarity of Reddit Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We re-use the data scraped and pre-processed in Module 1 for Cosine Similarity.\n",
    "\n",
    "First step of preprocessing would be converting each comment into an array of tokens, lemmatizing the tokens and removing unwanted characters/patterns and stop words. Tokenization is the process of breaking down text into words. We then apply Lemmatization to change multiple inflected forms of words into its base form. We then remove any commonly occuring stop words from the NLTK english dictionary. We have also removed stop words corresponding to the numbers, URLs and leftover components from lemmatized words. We then use TF-DIF to vectorize the simple text generated through pre-processing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWRf1HYCftRH"
   },
   "source": [
    "### Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGc-iuSaccWP"
   },
   "source": [
    "To get a Tf-idf matrix, first count word occurrences by document. This is transformed into a document-term matrix (dtm). This is also just called a term frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5365,
     "status": "ok",
     "timestamp": 1607977147274,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "BT5uERtOfqIO",
    "outputId": "6bc3794a-713f-4a52-cadb-780abfd4f4b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.8 s, sys: 150 ms, total: 4.95 s\n",
      "Wall time: 4.97 s\n",
      "(388, 736846)\n"
     ]
    }
   ],
   "source": [
    "# defining regex pattern\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "\n",
    "# initializing TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords_list, token_pattern=pattern,  ngram_range=(1,3))\n",
    "%time X= tfidf.fit_transform(train['simple_text'])\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVMEHDnqjEbo"
   },
   "source": [
    "dist is defined as 1 - the cosine similarity of each document. Cosine similarity is measured against the tf-idf matrix and can be used to generate a measure of similarity between each document and the other documents in the corpus . Subtracting it from 1 provides cosine distance which I will use for plotting on a euclidean (2-dimensional) plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1607977150456,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "YbR-b8i3f1sI",
    "outputId": "5022dad1-d0e4-4ba5-96bb-84b415dc02c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00000000e+00  1.00000000e+00 ...  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 1.00000000e+00  6.10622664e-15  9.95853353e-01 ...  9.91853785e-01\n",
      "   9.97274918e-01  1.00000000e+00]\n",
      " [ 1.00000000e+00  9.95853353e-01 -4.88498131e-15 ...  9.53299186e-01\n",
      "   9.95172024e-01  1.00000000e+00]\n",
      " ...\n",
      " [ 1.00000000e+00  9.91853785e-01  9.53299186e-01 ...  1.11022302e-16\n",
      "   9.97039423e-01  1.00000000e+00]\n",
      " [ 1.00000000e+00  9.97274918e-01  9.95172024e-01 ...  9.97039423e-01\n",
      "   4.66293670e-15  1.00000000e+00]\n",
      " [ 1.00000000e+00  1.00000000e+00  1.00000000e+00 ...  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(X)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1607977150771,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "g-OfnR06m1f0",
    "outputId": "a933e801-c69c-42af-d42a-e8e44706a812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 388 posts have been collected\n"
     ]
    }
   ],
   "source": [
    "num_posts = len(train.simple_text)\n",
    "print(\"A total of \" + str(num_posts) + \" posts have been collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 1001,
     "status": "ok",
     "timestamp": 1607977152651,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "qW3b5eElm9YO",
    "outputId": "f333136a-ad41-4b51-f365-cb8dd0f901c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 75078 pairs\n",
      "Displaying first 3 pairs: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2), (0, 3)]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Displaying last 3 pairs: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(385, 386), (385, 387), (386, 387)]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "postids = train.index\n",
    "\n",
    "# create a dictionary\n",
    "post_dict = dict(zip(postids, train.simple_text))\n",
    "\n",
    "# get all the post ids in a list\n",
    "ids = list(post_dict.keys())\n",
    "\n",
    "# create all possible pairs\n",
    "pairs = []\n",
    "# create a list of tuples\n",
    "for i, v in enumerate(ids):\n",
    "    for j in ids[i+1:]:\n",
    "        pairs.append((ids[i], j))\n",
    "\n",
    "print(\"There are a total of \" + str(len(pairs)) + \" pairs\")\n",
    "print(\"Displaying first 3 pairs: \")\n",
    "display(pairs[:3])\n",
    "print(\"....\")\n",
    "print(\"Displaying last 3 pairs: \")\n",
    "display(pairs[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1607977152953,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "WXdDNZO0neC9"
   },
   "outputs": [],
   "source": [
    "#Compute cosine similarity for each pair of reddit posts\n",
    "def compute_cosine_similarity(pair):\n",
    "\n",
    "    # extract the indexes from the pair\n",
    "    post1, post2 = pair\n",
    "\n",
    "    # get the feature matrix of the document\n",
    "    post1_fm = feature_matrix.toarray()[post1]\n",
    "    post2_fm = feature_matrix.toarray()[post2]\n",
    "\n",
    "    # compute cosine similarity manually\n",
    "    manual_cosine_similarity = np.dot(post1_fm, post2_fm)\n",
    "\n",
    "    return manual_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1116,
     "status": "ok",
     "timestamp": 1607977155632,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "_ZGa1unooDiK",
    "outputId": "3889c7f5-616c-47b6-f1e6-1dc9568e1906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 25640)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1,1))\n",
    "vectorizer\n",
    "# calculate the feature matrix\n",
    "feature_matrix = vectorizer.fit_transform(train.simple_text).astype(float)\n",
    "\n",
    "# display the shape of feature matrix\n",
    "display(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "executionInfo": {
     "elapsed": 3389812,
     "status": "ok",
     "timestamp": 1607980544971,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "r0szP7UCnqii",
    "outputId": "9dbf97a8-e895-4ea7-d975-10e263866e7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 4)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair  similarity\n",
       "0  (0, 1)         0.0\n",
       "1  (0, 2)         0.0\n",
       "2  (0, 3)         0.0\n",
       "3  (0, 4)         0.0\n",
       "4  (0, 5)         0.0"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75073</th>\n",
       "      <td>(384, 386)</td>\n",
       "      <td>0.027308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75074</th>\n",
       "      <td>(384, 387)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75075</th>\n",
       "      <td>(385, 386)</td>\n",
       "      <td>0.008438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75076</th>\n",
       "      <td>(385, 387)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75077</th>\n",
       "      <td>(386, 387)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pair  similarity\n",
       "75073  (384, 386)    0.027308\n",
       "75074  (384, 387)    0.000000\n",
       "75075  (385, 386)    0.008438\n",
       "75076  (385, 387)    0.000000\n",
       "75077  (386, 387)    0.000000"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairwise_cosine_similarity = [compute_cosine_similarity(pair) for pair in pairs]\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame({'pair': pairs, 'similarity': pairwise_cosine_similarity})\n",
    "display(df.head())\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "executionInfo": {
     "elapsed": 3383994,
     "status": "ok",
     "timestamp": 1607980545034,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "p7yVzDAuzqXi"
   },
   "outputs": [],
   "source": [
    "#Restructing dataframes for the heatmap below\n",
    "df[['pair1', 'pair2']] = pd.DataFrame(df['pair'].tolist(), index=df.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "executionInfo": {
     "elapsed": 3383134,
     "status": "ok",
     "timestamp": 1607980545036,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "GE2Vkuppzyld"
   },
   "outputs": [],
   "source": [
    "df2=df\n",
    "df2=df2.drop(['pair'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1607981048744,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "_DIYQTW96OlN"
   },
   "outputs": [],
   "source": [
    "#Selecting only the pairs with a similarity score>0.5 to be displayed in the heatmap\n",
    "df3=df2.loc[df2.similarity>0.5]\n",
    "df3=df3.sort_values(by=['similarity'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1607981053516,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "WTfsQoXSI6jD",
    "outputId": "2db91347-e5e8-4072-b9e0-592e98e6dd65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>pair1</th>\n",
       "      <th>pair2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57939</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>202</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36178</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>108</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36111</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>108</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61925</th>\n",
       "      <td>0.789891</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41084</th>\n",
       "      <td>0.730820</td>\n",
       "      <td>126</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44498</th>\n",
       "      <td>0.716653</td>\n",
       "      <td>140</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17050</th>\n",
       "      <td>0.708596</td>\n",
       "      <td>46</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63962</th>\n",
       "      <td>0.694868</td>\n",
       "      <td>238</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23519</th>\n",
       "      <td>0.682009</td>\n",
       "      <td>66</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72793</th>\n",
       "      <td>0.661716</td>\n",
       "      <td>319</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19873</th>\n",
       "      <td>0.646901</td>\n",
       "      <td>55</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45652</th>\n",
       "      <td>0.644851</td>\n",
       "      <td>144</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63828</th>\n",
       "      <td>0.634956</td>\n",
       "      <td>237</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>0.611450</td>\n",
       "      <td>55</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.600629</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>0.595651</td>\n",
       "      <td>53</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72354</th>\n",
       "      <td>0.591125</td>\n",
       "      <td>313</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45473</th>\n",
       "      <td>0.584496</td>\n",
       "      <td>144</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49246</th>\n",
       "      <td>0.579645</td>\n",
       "      <td>160</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>0.579130</td>\n",
       "      <td>7</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61926</th>\n",
       "      <td>0.574087</td>\n",
       "      <td>225</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72312</th>\n",
       "      <td>0.571054</td>\n",
       "      <td>313</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32235</th>\n",
       "      <td>0.569555</td>\n",
       "      <td>94</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29302</th>\n",
       "      <td>0.568976</td>\n",
       "      <td>84</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50745</th>\n",
       "      <td>0.565128</td>\n",
       "      <td>166</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19355</th>\n",
       "      <td>0.557565</td>\n",
       "      <td>53</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20057</th>\n",
       "      <td>0.550588</td>\n",
       "      <td>55</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>0.549887</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58724</th>\n",
       "      <td>0.547687</td>\n",
       "      <td>206</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>0.547670</td>\n",
       "      <td>66</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61975</th>\n",
       "      <td>0.546587</td>\n",
       "      <td>225</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53125</th>\n",
       "      <td>0.545793</td>\n",
       "      <td>177</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58663</th>\n",
       "      <td>0.545195</td>\n",
       "      <td>206</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8061</th>\n",
       "      <td>0.536140</td>\n",
       "      <td>21</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19807</th>\n",
       "      <td>0.534678</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73039</th>\n",
       "      <td>0.534037</td>\n",
       "      <td>323</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41774</th>\n",
       "      <td>0.533764</td>\n",
       "      <td>129</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42031</th>\n",
       "      <td>0.533408</td>\n",
       "      <td>130</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22363</th>\n",
       "      <td>0.532867</td>\n",
       "      <td>62</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63880</th>\n",
       "      <td>0.532073</td>\n",
       "      <td>237</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63838</th>\n",
       "      <td>0.529081</td>\n",
       "      <td>237</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32225</th>\n",
       "      <td>0.524719</td>\n",
       "      <td>94</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45617</th>\n",
       "      <td>0.524190</td>\n",
       "      <td>144</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19874</th>\n",
       "      <td>0.523611</td>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73063</th>\n",
       "      <td>0.522650</td>\n",
       "      <td>324</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29014</th>\n",
       "      <td>0.518794</td>\n",
       "      <td>83</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29250</th>\n",
       "      <td>0.515099</td>\n",
       "      <td>84</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68911</th>\n",
       "      <td>0.514821</td>\n",
       "      <td>276</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50693</th>\n",
       "      <td>0.514764</td>\n",
       "      <td>166</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29103</th>\n",
       "      <td>0.512146</td>\n",
       "      <td>84</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22493</th>\n",
       "      <td>0.509783</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57318</th>\n",
       "      <td>0.509357</td>\n",
       "      <td>199</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40966</th>\n",
       "      <td>0.503307</td>\n",
       "      <td>126</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>0.503284</td>\n",
       "      <td>5</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32149</th>\n",
       "      <td>0.503269</td>\n",
       "      <td>94</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53163</th>\n",
       "      <td>0.503094</td>\n",
       "      <td>178</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42000</th>\n",
       "      <td>0.501287</td>\n",
       "      <td>130</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>0.500990</td>\n",
       "      <td>8</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       similarity  pair1  pair2\n",
       "57939    1.000000    202    269\n",
       "36178    1.000000    108    269\n",
       "36111    1.000000    108    202\n",
       "61925    0.789891    225    276\n",
       "41084    0.730820    126    324\n",
       "44498    0.716653    140    189\n",
       "17050    0.708596     46    330\n",
       "63962    0.694868    238    298\n",
       "23519    0.682009     66    189\n",
       "72793    0.661716    319    381\n",
       "19873    0.646901     55    129\n",
       "45652    0.644851    144    365\n",
       "63828    0.634956    237    313\n",
       "19981    0.611450     55    237\n",
       "1974     0.600629      5     55\n",
       "19304    0.595651     53    225\n",
       "72354    0.591125    313    365\n",
       "45473    0.584496    144    186\n",
       "49246    0.579645    160    207\n",
       "2886     0.579130      7    206\n",
       "61926    0.574087    225    277\n",
       "72312    0.571054    313    323\n",
       "32235    0.569555     94    323\n",
       "29302    0.568976     84    365\n",
       "50745    0.565128    166    365\n",
       "19355    0.557565     53    276\n",
       "20057    0.550588     55    313\n",
       "2048     0.549887      5    129\n",
       "58724    0.547687    206    324\n",
       "23470    0.547670     66    140\n",
       "61975    0.546587    225    326\n",
       "53125    0.545793    177    380\n",
       "58663    0.545195    206    263\n",
       "8061     0.536140     21    166\n",
       "19807    0.534678     55     63\n",
       "73039    0.534037    323    365\n",
       "41774    0.533764    129    237\n",
       "42031    0.533408    130    237\n",
       "22363    0.532867     62    323\n",
       "63880    0.532073    237    365\n",
       "63838    0.529081    237    323\n",
       "32225    0.524719     94    313\n",
       "45617    0.524190    144    330\n",
       "19874    0.523611     55    130\n",
       "73063    0.522650    324    326\n",
       "29014    0.518794     83    380\n",
       "29250    0.515099     84    313\n",
       "68911    0.514821    276    326\n",
       "50693    0.514764    166    313\n",
       "29103    0.512146     84    166\n",
       "22493    0.509783     63    129\n",
       "57318    0.509357    199    206\n",
       "40966    0.503307    126    206\n",
       "2156     0.503284      5    237\n",
       "32149    0.503269     94    237\n",
       "53163    0.503094    178    209\n",
       "42000    0.501287    130    206\n",
       "3292     0.500990      8    233"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfDMhZU1S7iK"
   },
   "source": [
    "### Create the heatmap to show the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1607982762331,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "1O2SDVFKPJIk"
   },
   "outputs": [],
   "source": [
    "heatmap1_data = pd.pivot_table(df3, values='similarity', \n",
    "                     index=['pair1'], \n",
    "                     columns='pair2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "executionInfo": {
     "elapsed": 1364,
     "status": "ok",
     "timestamp": 1607982908151,
     "user": {
      "displayName": "Lalitanjali Bondili",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GifVUqE328BGabTj8PvdYbP6ahvza0Uf73HpgDDDg=s64",
      "userId": "06050275606006925914"
     },
     "user_tz": 300
    },
    "id": "Xa4U5xyDPeRH",
    "outputId": "4ed26b10-db91-462d-dbf3-a05bb30fde2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa05913a390>"
      ]
     },
     "execution_count": 186,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap1_data, cmap=\"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZaxafbuPwme"
   },
   "source": [
    "\n",
    "From the heatmap above, we see that comments from subreddit 108, 202 and 269 are extremely similar to each other as they have a similarity score ~ 1.  Comments from subreddit 276 and 225 also are similar with a similarity score of 0.75. Out of all the combinations of over 330 different posts, fewer than 10 posts have a similarity score of 0.75. This shows that reddit is already doing a good job at handling redundancies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: LDA Topic Modeling\n",
    "\n",
    "LDA is used to extract topics from a document corpus. It can be used to build topics per document model or words per topic model. These are modeled as Dirichlet distributions.\n",
    "The LDA model generates topics which are specific groups of words that can be used to represent the topic of a document/corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We used subreddit datasets(news, worldnews, askscience, and science to perform topic modeling using LDA. We scraped all the hot and top posts from the four subreddits to create the dataset. We will be using the subreddit post title and its body for LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter credentials to connect to the reddit client\n",
    "reddit = praw.Reddit(username = 'CandleZealousideal25',            \n",
    "password = 'Meens20!',            \n",
    "client_id = 'bn6D7tN21aOp-w',            \n",
    "client_secret = 'qs-250PRYA3Me7QPM6nR9y3MPDCtrA',            \n",
    "user_agent = 'Python chatbot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1607797000844,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "CtebSzL2xtDK"
   },
   "outputs": [],
   "source": [
    "def get_BOW_per_post(subs, limit):\n",
    "  posts = []\n",
    "\n",
    "  for sub in subs:\n",
    "    print(sub)\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    hot_python = set(list(subreddit.top('all', limit=limit))+list(subreddit.hot(limit=limit))) \n",
    "    \n",
    "    for i, submission in enumerate(hot_python): \n",
    "      posts.append([submission.title, submission.score, submission.id, submission.subreddit, submission.url, submission.num_comments, submission.selftext, submission.created])\n",
    "    \n",
    "  posts = pd.DataFrame(posts)\n",
    "\n",
    "  return posts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "executionInfo": {
     "elapsed": 5999,
     "status": "ok",
     "timestamp": 1607797014513,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "AXa463jbx1Y1",
    "outputId": "081a07a4-05a3-47e0-c45c-207303dcf14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "askscience\n",
      "science\n",
      "worldnews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>URL</th>\n",
       "      <th>NumComments</th>\n",
       "      <th>Body</th>\n",
       "      <th>Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump administration delays endangered species...</td>\n",
       "      <td>10813</td>\n",
       "      <td>kdtbpx</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.cbsnews.com/news/trump-administrat...</td>\n",
       "      <td>514</td>\n",
       "      <td></td>\n",
       "      <td>1.608092e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Senator John McCain has passed away at...</td>\n",
       "      <td>154798</td>\n",
       "      <td>9abi3e</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.abc15.com/news/state/arizona-senat...</td>\n",
       "      <td>11517</td>\n",
       "      <td></td>\n",
       "      <td>1.535272e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F.C.C. Announces Plan to Repeal Net Neutrality</td>\n",
       "      <td>177999</td>\n",
       "      <td>7ej943</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.nytimes.com/2017/11/21/technology/...</td>\n",
       "      <td>10840</td>\n",
       "      <td></td>\n",
       "      <td>1.511312e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most child sexual abuse gangs made up of white...</td>\n",
       "      <td>154</td>\n",
       "      <td>kebt8f</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.theguardian.com/politics/2020/dec/...</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td>1.608163e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghislane Maxwell, long-time friend and confida...</td>\n",
       "      <td>165167</td>\n",
       "      <td>hjwwxh</td>\n",
       "      <td>news</td>\n",
       "      <td>https://nbcnews.to/38tf3LC</td>\n",
       "      <td>13036</td>\n",
       "      <td></td>\n",
       "      <td>1.593725e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Score      ID  \\\n",
       "0  Trump administration delays endangered species...   10813  kdtbpx   \n",
       "1  Arizona Senator John McCain has passed away at...  154798  9abi3e   \n",
       "2     F.C.C. Announces Plan to Repeal Net Neutrality  177999  7ej943   \n",
       "3  Most child sexual abuse gangs made up of white...     154  kebt8f   \n",
       "4  Ghislane Maxwell, long-time friend and confida...  165167  hjwwxh   \n",
       "\n",
       "  Subreddit                                                URL  NumComments  \\\n",
       "0      news  https://www.cbsnews.com/news/trump-administrat...          514   \n",
       "1      news  https://www.abc15.com/news/state/arizona-senat...        11517   \n",
       "2      news  https://www.nytimes.com/2017/11/21/technology/...        10840   \n",
       "3      news  https://www.theguardian.com/politics/2020/dec/...          100   \n",
       "4      news                         https://nbcnews.to/38tf3LC        13036   \n",
       "\n",
       "  Body       Created  \n",
       "0       1.608092e+09  \n",
       "1       1.535272e+09  \n",
       "2       1.511312e+09  \n",
       "3       1.608163e+09  \n",
       "4       1.593725e+09  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs=['news', 'askscience', 'science', 'worldnews']\n",
    "posts = get_BOW_per_post(subs, 20)\n",
    "posts.columns = ['Title', 'Score', 'ID', 'Subreddit', 'URL', 'NumComments', 'Body', 'Created']\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cleaned each post title and its by processing the following steps:\n",
    "\n",
    " 1) converting all text to lowercase\n",
    " \n",
    " 2) Removing any hyperlinks or URLs using regular expression\n",
    " \n",
    " 3) Tokenizing words in each post into tokens \n",
    " \n",
    " 4) Lemmatizing to convert any inflected forms of words into its base form\n",
    " \n",
    " 5) Remove commonly occurring stop words as found in the english NLTK dictionary along with [http', 'com', 'www', 'askscience'] and other punctuation used in URLS or http text\n",
    "\n",
    "When then used the simple text created from the preprocessing module above and converted it into its vectorized form using the TF-DIF vectorizer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1607797022087,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "G18Zb7AI0Mrz",
    "outputId": "80541175-dd78-4179-8b2f-e72e798814af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/meenu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>ID</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>URL</th>\n",
       "      <th>NumComments</th>\n",
       "      <th>Body</th>\n",
       "      <th>Created</th>\n",
       "      <th>BOW_Title</th>\n",
       "      <th>BOW_Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump administration delays endangered species...</td>\n",
       "      <td>10813</td>\n",
       "      <td>kdtbpx</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.cbsnews.com/news/trump-administrat...</td>\n",
       "      <td>514</td>\n",
       "      <td></td>\n",
       "      <td>1.608092e+09</td>\n",
       "      <td>[trump, administration, delay, endangered, spe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Senator John McCain has passed away at...</td>\n",
       "      <td>154798</td>\n",
       "      <td>9abi3e</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.abc15.com/news/state/arizona-senat...</td>\n",
       "      <td>11517</td>\n",
       "      <td></td>\n",
       "      <td>1.535272e+09</td>\n",
       "      <td>[arizona, senator, john, mccain, ha, passed, a...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F.C.C. Announces Plan to Repeal Net Neutrality</td>\n",
       "      <td>177999</td>\n",
       "      <td>7ej943</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.nytimes.com/2017/11/21/technology/...</td>\n",
       "      <td>10840</td>\n",
       "      <td></td>\n",
       "      <td>1.511312e+09</td>\n",
       "      <td>[f., c., c., announces, plan, repeal, net, neu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Most child sexual abuse gangs made up of white...</td>\n",
       "      <td>154</td>\n",
       "      <td>kebt8f</td>\n",
       "      <td>news</td>\n",
       "      <td>https://www.theguardian.com/politics/2020/dec/...</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td>1.608163e+09</td>\n",
       "      <td>[child, sexual, abuse, gang, made, white, men,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghislane Maxwell, long-time friend and confida...</td>\n",
       "      <td>165167</td>\n",
       "      <td>hjwwxh</td>\n",
       "      <td>news</td>\n",
       "      <td>https://nbcnews.to/38tf3LC</td>\n",
       "      <td>13036</td>\n",
       "      <td></td>\n",
       "      <td>1.593725e+09</td>\n",
       "      <td>[ghislane, maxwell, long-time, friend, confida...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Score      ID  \\\n",
       "0  Trump administration delays endangered species...   10813  kdtbpx   \n",
       "1  Arizona Senator John McCain has passed away at...  154798  9abi3e   \n",
       "2     F.C.C. Announces Plan to Repeal Net Neutrality  177999  7ej943   \n",
       "3  Most child sexual abuse gangs made up of white...     154  kebt8f   \n",
       "4  Ghislane Maxwell, long-time friend and confida...  165167  hjwwxh   \n",
       "\n",
       "  Subreddit                                                URL  NumComments  \\\n",
       "0      news  https://www.cbsnews.com/news/trump-administrat...          514   \n",
       "1      news  https://www.abc15.com/news/state/arizona-senat...        11517   \n",
       "2      news  https://www.nytimes.com/2017/11/21/technology/...        10840   \n",
       "3      news  https://www.theguardian.com/politics/2020/dec/...          100   \n",
       "4      news                         https://nbcnews.to/38tf3LC        13036   \n",
       "\n",
       "  Body       Created                                          BOW_Title  \\\n",
       "0       1.608092e+09  [trump, administration, delay, endangered, spe...   \n",
       "1       1.535272e+09  [arizona, senator, john, mccain, ha, passed, a...   \n",
       "2       1.511312e+09  [f., c., c., announces, plan, repeal, net, neu...   \n",
       "3       1.608163e+09  [child, sexual, abuse, gang, made, white, men,...   \n",
       "4       1.593725e+09  [ghislane, maxwell, long-time, friend, confida...   \n",
       "\n",
       "  BOW_Body  \n",
       "0       []  \n",
       "1       []  \n",
       "2       []  \n",
       "3       []  \n",
       "4       []  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_and_tokenize(row):\n",
    "\n",
    "  stopwords_list = nltk.corpus.stopwords.words('english')\n",
    "  web_punctuation = [\" \", \"  \", \"#\", \",\", \"|\", \"-\", \"‘\", \"’\", \";\", \"(\", \")\", \".\", \":\", \"¿\", \"?\", '“', \"/\",\n",
    "    '”', '\"', \"'\", \"%\", \"•\", \"«\", \"»\", '``', \"''\", \"--\"]\n",
    "  stopwords_list += list(string.punctuation) + ['http', 'com', 'www', 'askscience'] + web_punctuation\n",
    "  lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "  # lowercase\n",
    "  output = row.lower().replace('.','. ').replace('  ',' ') # .replace('/',' / ')\n",
    "  \n",
    "  # remove links\n",
    "  output = re.sub(r'\\([^)]*\\)', '', output)\n",
    "  output = re.sub(r'http\\S+\\s+', '', output)  \n",
    "\n",
    "  # tokenize\n",
    "  output_tokens = nltk.tokenize.word_tokenize(output) # output.map(nltk.tokenize.word_tokenize)\n",
    "\n",
    "  # lemmatization\n",
    "  output_lemmatized = [lemmatizer.lemmatize(i) for i in output_tokens]\n",
    "\n",
    "  # stopwords\n",
    "  def simplify(tokens):\n",
    "    simple_text = []\n",
    "    for i in tokens:\n",
    "        if i not in stopwords_list: #removing stopwords\n",
    "            if i not in string.punctuation: #removing punctuation\n",
    "                simple_text.append(i)\n",
    "    return simple_text\n",
    "\n",
    "  output_clean = simplify(output_lemmatized)\n",
    "  return output_clean\n",
    "\n",
    "posts['BOW_Title'] = posts['Title'].apply(clean_and_tokenize)\n",
    "posts['BOW_Body'] = posts['Body'].apply(clean_and_tokenize)\n",
    "\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1607796778877,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "qn-cnQQoJ67o",
    "outputId": "426bd9ac-8dc8-472b-8ba1-5b8d9bc0ab50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Subreddit(display_name='news'),\n",
       "       Subreddit(display_name='askscience'),\n",
       "       Subreddit(display_name='science'),\n",
       "       Subreddit(display_name='worldnews')], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['Subreddit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1607794863710,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "kz5IIS1-CqBy",
    "outputId": "66528c5b-5ef0-4e89-8916-a95a12c56c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRloeXkP2Zqi"
   },
   "source": [
    "# LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the vectorized simple text into a bag of words model — which is basically a dictionary where the key is the word and value is the number of times that word occurs in the entire corpus.  We use the gensim.corpora.dictionary to create these id to word tokens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1607792839272,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "tusx-XSl2b7s",
    "outputId": "acf44bee-c64d-4055-8cb3-1a15c44ee621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm=None) #Ignoring the norm (ie. no Euclidean norm)\n",
    "X = vectorizer.fit_transform(posts.Title)\n",
    "\n",
    "print(type(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1607798054151,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "Q0hS_1yj7D3E"
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import pprint\n",
    "\n",
    "#Function to process LDA from document tokens \n",
    "\n",
    "def LDA_from_doc_tokens(doc_tokens, num_topics, passes = 20, alpha = 'auto', eta = 'auto', printoff = False, pprint_num = 6):\n",
    "  \n",
    "  id2word = corpora.Dictionary(doc_tokens)\n",
    "  id2word.filter_extremes(no_below=3, no_above=.8)\n",
    "  id2word.filter_n_most_frequent(10)\n",
    "  # generating term frequency for each play\n",
    "  corpus = [id2word.doc2bow(text) for text in doc_tokens]\n",
    "\n",
    "  lda = models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word = id2word, passes=passes, random_state = 0)\n",
    "\n",
    "  if printoff:\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_topics=printoff, num_words=15))\n",
    "\n",
    "  return lda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1395,
     "status": "ok",
     "timestamp": 1607798090245,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "dsbsgtdUO2p2",
    "outputId": "24ac963f-6bcf-4e28-eabc-4c0a5be1f58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.091*\"dy\" + 0.062*\"doe\" + 0.062*\"away\" + 0.062*\"animal\" + '\n",
      "        '0.062*\"lower\" + 0.062*\"complex\" + 0.061*\"brain\" + 0.032*\"leader\" + '\n",
      "        '0.032*\"virus\" + 0.032*\"first\" + 0.032*\"world\" + 0.032*\"instead\" + '\n",
      "        '0.032*\"region\" + 0.032*\"black\" + 0.032*\"50\"'),\n",
      "    (   14,\n",
      "        '0.135*\"covid\" + 0.095*\"doe\" + 0.095*\"n\\'t\" + 0.071*\"banned\" + '\n",
      "        '0.071*\"employee\" + 0.048*\"year\" + 0.042*\"test\" + 0.025*\"space\" + '\n",
      "        '0.025*\"something\" + 0.025*\"change\" + 0.025*\"50\" + 0.025*\"official\" + '\n",
      "        '0.025*\"positive\" + 0.025*\"million\" + 0.025*\"city\"'),\n",
      "    (   15,\n",
      "        '0.092*\"hawking\" + 0.092*\"stephen\" + 0.062*\"day\" + 0.032*\"first\" + '\n",
      "        '0.032*\"police\" + 0.032*\"system\" + 0.032*\"suggests\" + 0.032*\"air\" + '\n",
      "        '0.032*\"coronavirus\" + 0.032*\"fight\" + 0.032*\"le\" + 0.032*\"led\" + '\n",
      "        '0.032*\"light\" + 0.032*\"99\" + 0.032*\"kill\"'),\n",
      "    (   9,\n",
      "        '0.073*\"u\" + 0.070*\"wa\" + 0.070*\"world\" + 0.052*\"earth\" + '\n",
      "        '0.052*\"around\" + 0.035*\"leader\" + 0.018*\"president\" + '\n",
      "        '0.018*\"coronavirus\" + 0.018*\"led\" + 0.018*\"mass\" + 0.018*\"state\" + '\n",
      "        '0.018*\"drop\" + 0.018*\"cost\" + 0.018*\"pay\" + 0.018*\"suggests\"'),\n",
      "    (   10,\n",
      "        '0.111*\"net\" + 0.111*\"neutrality\" + 0.056*\"u\" + 0.056*\"fight\" + '\n",
      "        '0.056*\"help\" + 0.056*\"rest\" + 0.056*\"need\" + 0.029*\"mass\" + '\n",
      "        '0.029*\"product\" + 0.029*\"see\" + 0.029*\"official\" + 0.029*\"drug\" + '\n",
      "        '0.029*\"led\" + 0.029*\"2\" + 0.029*\"legal\"'),\n",
      "    (   19,\n",
      "        '0.087*\"year\" + 0.087*\"1\" + 0.087*\"billion\" + 0.055*\"doe\" + '\n",
      "        '0.055*\"see\" + 0.030*\"space\" + 0.030*\"due\" + 0.030*\"light\" + '\n",
      "        '0.030*\"travel\" + 0.030*\"history\" + 0.030*\"death\" + 0.030*\"legal\" + '\n",
      "        '0.030*\"air\" + 0.030*\"wa\" + 0.030*\"cause\"'),\n",
      "    (   17,\n",
      "        '0.080*\"99\" + 0.080*\"quality\" + 0.080*\"like\" + 0.050*\"specie\" + '\n",
      "        '0.041*\"winter\" + 0.041*\"world\" + 0.041*\"tree\" + 0.041*\"region\" + '\n",
      "        '0.041*\"state\" + 0.041*\"n\\'t\" + 0.041*\"make\" + 0.041*\"kill\" + '\n",
      "        '0.041*\"answer\" + 0.041*\"question\" + 0.041*\"vaccine\"'),\n",
      "    (   8,\n",
      "        '0.177*\"human\" + 0.119*\"report\" + 0.089*\"game\" + 0.060*\"evidence\" + '\n",
      "        '0.060*\"make\" + 0.060*\"thought\" + 0.060*\"use\" + 0.053*\"specie\" + '\n",
      "        '0.031*\"serious\" + 0.031*\"day\" + 0.031*\"light\" + 0.031*\"made\" + '\n",
      "        '0.031*\"using\" + 0.002*\"gas\" + 0.002*\"u\"'),\n",
      "    (   18,\n",
      "        '0.075*\"million\" + 0.075*\"ask\" + 0.075*\"one\" + 0.075*\"dead\" + '\n",
      "        '0.038*\"first\" + 0.038*\"black\" + 0.038*\"away\" + 0.038*\"50\" + '\n",
      "        '0.038*\"evidence\" + 0.038*\"region\" + 0.038*\"uk\" + 0.038*\"china\" + '\n",
      "        '0.038*\"instead\" + 0.038*\"cause\" + 0.038*\"worker\"'),\n",
      "    (   12,\n",
      "        '0.097*\"positive\" + 0.097*\"coronavirus\" + 0.066*\"le\" + 0.066*\"greater\" '\n",
      "        '+ 0.066*\"health\" + 0.065*\"president\" + 0.065*\"china\" + 0.034*\"lower\" '\n",
      "        '+ 0.034*\"higher\" + 0.034*\"one\" + 0.034*\"year\" + 0.034*\"said\" + '\n",
      "        '0.034*\"test\" + 0.034*\"group\" + 0.034*\"game\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x1a559a7050>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating top 20 topics\n",
    "LDA_from_doc_tokens(posts['BOW_Title'], num_topics = 20, printoff = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "executionInfo": {
     "elapsed": 2241,
     "status": "ok",
     "timestamp": 1607797037536,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "PFB81SFI59A5",
    "outputId": "5445161d-1b71-4853-fb13-fd4516a86212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:260: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/ldavis.v1.0.0.js' mode='r' encoding='UTF-8'>\n",
      "  open(urls.LDAVIS_LOCAL, 'r').read()],\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:262: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/ldavis.v1.0.0.css' mode='r' encoding='UTF-8'>\n",
      "  open(urls.LDAVIS_CSS_LOCAL, 'r').read()],\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:264: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/d3.v3.min.js' mode='r' encoding='UTF-8'>\n",
      "  open(urls.D3_LOCAL, 'r').read()]}\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "127.0.0.1 - - [16/Dec/2020 15:27:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:27:13] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:27:13] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:27:13] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Visualization using pyLDAvis for top 20 topics\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "id2word = corpora.Dictionary(posts['BOW_Title'])\n",
    "id2word.filter_extremes(no_below=3)\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in posts['BOW_Title']]\n",
    "lda = models.ldamodel.LdaModel(corpus, num_topics=10, id2word = id2word, passes=20, random_state = 0)\n",
    "\n",
    "lda_visualization = pyLDAvis.gensim.prepare(lda, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.show(lda_visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "executionInfo": {
     "elapsed": 2027,
     "status": "ok",
     "timestamp": 1607797040751,
     "user": {
      "displayName": "Vanessa Moody",
      "photoUrl": "",
      "userId": "12001892803105742572"
     },
     "user_tz": 300
    },
    "id": "qsrVHFjGIviI",
    "outputId": "b8867b69-856c-4762-ff50-00842818e7bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:260: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/ldavis.v1.0.0.js' mode='r' encoding='UTF-8'>\n",
      "  open(urls.LDAVIS_LOCAL, 'r').read()],\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:262: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/ldavis.v1.0.0.css' mode='r' encoding='UTF-8'>\n",
      "  open(urls.LDAVIS_CSS_LOCAL, 'r').read()],\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py:264: ResourceWarning: unclosed file <_io.TextIOWrapper name='/Users/meenu/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/js/d3.v3.min.js' mode='r' encoding='UTF-8'>\n",
      "  open(urls.D3_LOCAL, 'r').read()]}\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "127.0.0.1 - - [16/Dec/2020 15:24:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:24:03] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:24:03] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Dec/2020 15:24:03] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "# Visualization using pyLDAvis for top 2 topics\n",
    "\n",
    "id2word = corpora.Dictionary(posts['BOW_Title'])\n",
    "id2word.filter_extremes(no_below=3)\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in posts['BOW_Title']]\n",
    "lda = models.ldamodel.LdaModel(corpus, num_topics=2, id2word = id2word, passes=20, random_state = 0)\n",
    "\n",
    "lda_visualization = pyLDAvis.gensim.prepare(lda, corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.show(lda_visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw-VzLuKJUVg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPyWcrwkYUiTt9ejTT2G/B0",
   "collapsed_sections": [],
   "name": "Text Summarization and Cosine Similarity v1",
   "provenance": [
    {
     "file_id": "1Wi7tjnGgF2lPGOqStSRaFgw0iHzjQ_Ro",
     "timestamp": 1607798576883
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
